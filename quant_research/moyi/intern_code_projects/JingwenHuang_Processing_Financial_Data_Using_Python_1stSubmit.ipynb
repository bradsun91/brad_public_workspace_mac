{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Check List\n",
    "\n",
    "1. Find tickers of current S&P500 companies - Completed\n",
    "2. From S&P 500 companies, select 5 top companies from each industry sector, based on companys’ market capitalization -- Completed\n",
    "3. Then rank these 5 top company in their own industry sector respectively based on their most important financial metrics -- Almost Completed (details below)\n",
    "\n",
    "3.1 Ranks Included\n",
    "\n",
    "'Financials': Return on Equity (ROE)\n",
    "'Utilities': Debt-To-Equity (D/E) Ratios\n",
    "'Health Care': Cash, FCF\n",
    "'Consumer Staples': EBITDA/EV\n",
    "'Energy': EBITDA/EV\n",
    "'Industrials': None\n",
    "'Materials': None\n",
    "'Communication Services': EPS growth\n",
    "'Consumer Discretionary': # Sales growth\n",
    "\n",
    "3.2 Ranks will be included further and the challenges faced\n",
    "\n",
    "(1). 'Communication Services': P/E ratio \n",
    "problems: I haven't get a way to know how to get historical market value per share \n",
    "\n",
    "(2) 'Information Technology': Price to Sales \n",
    "problems: don't know how to get historical marketcap\n",
    "\n",
    "(3) 'Real Estate': FFO | NAV \n",
    "problems: don't know how to calculate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yfinance\n",
    "import yfinance as yf\n",
    "#!pip install yahooquery\n",
    "from yahooquery import Ticker\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brad added on 20200820:\n",
    "sp500_tickers_location = \"/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/quant_research/sp500_tickers_updates/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find tickers of current S&P500 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_sp500_tickers():\n",
    "#     \"\"\"\n",
    "#     This is a function to save current stock ticker in S&P500\n",
    "    \n",
    "#     Input: None\n",
    "    \n",
    "#     Output:\n",
    "#     tickers: A list of ticker name of S&P500 stocks\n",
    "#     \"\"\"\n",
    "#     resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "#     soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "#     table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "#     ### Collect the Ticker Name from Wikipedia tables\n",
    "#     tickers = []\n",
    "#     for row in table.findAll('tr')[1:]:\n",
    "#         ticker = row.findAll('td')[0].text\n",
    "#         tickers.append(ticker)\n",
    "#     ### Remove the newline character from list\n",
    "#     sample_list = tickers\n",
    "#     converted_list = []\n",
    "#     for element in sample_list:\n",
    "#         converted_list.append(element.strip())\n",
    "#     ### In Yahoo Finance, the website uses '-' in ticker name instead of '.'\n",
    "#     ### Replace \".\" With \"-\"\n",
    "#     new_strings = []\n",
    "#     for string in converted_list:\n",
    "#         new_string = string.replace(\".\", \"-\")\n",
    "#         new_strings.append(new_string)\n",
    "#     tickers = new_strings\n",
    "    \n",
    "#     \"\"\"\n",
    "#     ### Save the Ticker into file\n",
    "#     with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "#         pickle.dump(tickers,f)    \n",
    "#     \"\"\"\n",
    "#     return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Call Function\n",
    "# tickers = save_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"length of tickers list:\", len(set(tickers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From S&P 500 companies, select 5 top companies from each industry sector, based on companys’ market capitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Sector Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Create a function to extract the \"sector\" of stocks in S&P 500\n",
    "# def save_sp500_sector():\n",
    "#     \"\"\"\n",
    "#     This is a function to save current stock sectors in S&P500\n",
    "    \n",
    "#     Input: None\n",
    "    \n",
    "#     Output:\n",
    "#     sectors: A list of sector name of S&P500 stocks\n",
    "#     \"\"\"\n",
    "#     resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "#     soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "#     table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "#     ### Collect the sectors Name from Wikipedia tables\n",
    "#     sectors = []\n",
    "#     for row in table.findAll('tr')[1:]:\n",
    "#         sector = row.findAll('td')[3].text\n",
    "#         sectors.append(sector)\n",
    "#     ### Remove the newline character from list\n",
    "#     sample_list = sectors\n",
    "#     converted_list = []\n",
    "#     for element in sample_list:\n",
    "#         converted_list.append(element.strip())\n",
    "#     sectors = converted_list\n",
    "    \n",
    "#     return sectors   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Create a dictionary including {ticker: sector}\n",
    "# if __name__ == \"__main__\":\n",
    "#     ## Run save_sp500_sector() funtion to extract sector\n",
    "#     sectors = save_sp500_sector()\n",
    "#     ## Make ticker as Key and sector as Value in dictionary\n",
    "#     ticker_sector_dic = {tickers[i]: sectors[i] for i in range(len(tickers))} \n",
    "#     print(\"length of dictionary\", len(ticker_sector_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Market Cap Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Mcaps_yf(tickers):\n",
    "    \"\"\"\n",
    "    This function is to extract the market captalization for each input stocks\n",
    "    \n",
    "    Input: \n",
    "    tickers: a list of tickers of stocks\n",
    "    Output:\n",
    "    mktCaps: a dictionary contains {ticker : mktCap}. ticker is key and market captalization is value. \n",
    "    \"\"\"\n",
    "    mktCaps = {}\n",
    "    for ticker in tickers:\n",
    "        print(\"Getting data for: \", ticker)\n",
    "        try:\n",
    "            msft = yf.Ticker(ticker)\n",
    "            mktCap = msft.info['marketCap']\n",
    "            # Adding a new key value pair\n",
    "            mktCaps.update( {ticker : mktCap} )\n",
    "            print(ticker, 'done') # check process\n",
    "        except:\n",
    "            pass\n",
    "    return mktCaps\n",
    "\n",
    "def getList(dict): \n",
    "    \"\"\"\n",
    "    Create the function to extra the key of dictionanry into list\n",
    "    \n",
    "    Input:\n",
    "    dict: a dictionary\n",
    "    Ouput:\n",
    "    a list of keys from the input dictionary\n",
    "    \"\"\"\n",
    "    return list(dict.keys()) \n",
    "\n",
    "def Diff(li1, li2): \n",
    "    \"\"\"\n",
    "    Identify the difference between two list\n",
    "    \n",
    "    Input: \n",
    "    two list of tickers\n",
    "    \n",
    "    Output:\n",
    "    a list of tickers that appears in one dictionary but doesn't appear in the other dictionary \n",
    "    \"\"\"\n",
    "    return (list(set(li1) - set(li2))) \n",
    "\n",
    "def get_Mcaps_yf_2(tickers_diff):\n",
    "    \"\"\"\n",
    "    This function is a backup method to extract the market captalization for each stocks that are not recognized by yf.Ticker function\n",
    "    \n",
    "    Input: \n",
    "    tickers_diff: a list of tickers of stocks that don't extract the market capitalization from funtion get_Mcaps_yf(tickers)\n",
    "    Output:\n",
    "    mktCaps_diff: a dictionary contains {ticker : mktCap}. ticker is key and market captalization is value. \n",
    "    \"\"\"\n",
    "    mktCaps_diff = {}\n",
    "    for ticker in tickers_diff:\n",
    "        try:\n",
    "            mktCap = Ticker(ticker).summary_detail[ticker]['marketCap']\n",
    "            mktCaps_diff.update( {ticker : mktCap} )\n",
    "        except:\n",
    "            pass\n",
    "    return mktCaps_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_df = pd.read_csv(sp500_tickers_location+'sp500.csv')\n",
    "tickers = list(tickers_df['Tickers'])\n",
    "\n",
    "sectors_df = pd.read_csv(sp500_tickers_location + \"sp500_sectors.csv\")\n",
    "ticker_sector_dic = sectors_df.set_index('ticker').T.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for:  MMM\n",
      "Getting data for:  ABT\n",
      "ABT done\n",
      "Getting data for:  ABBV\n",
      "Getting data for:  ABMD\n",
      "Getting data for:  ACN\n",
      "Getting data for:  ATVI\n",
      "Getting data for:  ADBE\n",
      "Getting data for:  AMD\n",
      "Getting data for:  AAP\n",
      "Getting data for:  AES\n",
      "Getting data for:  AFL\n",
      "Getting data for:  A\n",
      "Getting data for:  APD\n",
      "Getting data for:  AKAM\n",
      "Getting data for:  ALK\n",
      "Getting data for:  ALB\n",
      "Getting data for:  ARE\n",
      "Getting data for:  ALXN\n",
      "Getting data for:  ALGN\n",
      "Getting data for:  ALLE\n",
      "Getting data for:  LNT\n",
      "Getting data for:  ALL\n",
      "Getting data for:  GOOGL\n",
      "Getting data for:  GOOG\n",
      "Getting data for:  MO\n",
      "Getting data for:  AMZN\n",
      "Getting data for:  AMCR\n",
      "Getting data for:  AEE\n",
      "Getting data for:  AAL\n",
      "Getting data for:  AEP\n",
      "Getting data for:  AXP\n",
      "Getting data for:  AIG\n",
      "Getting data for:  AMT\n",
      "Getting data for:  AWK\n",
      "Getting data for:  AMP\n",
      "Getting data for:  ABC\n",
      "Getting data for:  AME\n",
      "Getting data for:  AMGN\n",
      "Getting data for:  APH\n",
      "Getting data for:  ADI\n",
      "Getting data for:  ANSS\n",
      "Getting data for:  ANTM\n",
      "Getting data for:  AON\n",
      "Getting data for:  AOS\n",
      "Getting data for:  APA\n",
      "Getting data for:  AIV\n",
      "Getting data for:  AAPL\n",
      "Getting data for:  AMAT\n",
      "Getting data for:  APTV\n",
      "Getting data for:  ADM\n",
      "Getting data for:  ANET\n",
      "Getting data for:  AJG\n",
      "Getting data for:  AIZ\n",
      "Getting data for:  T\n",
      "Getting data for:  ATO\n",
      "Getting data for:  ADSK\n",
      "Getting data for:  ADP\n",
      "Getting data for:  AZO\n",
      "Getting data for:  AVB\n",
      "Getting data for:  AVY\n",
      "Getting data for:  BKR\n",
      "Getting data for:  BLL\n",
      "Getting data for:  BAC\n",
      "Getting data for:  BK\n",
      "Getting data for:  BAX\n",
      "Getting data for:  BDX\n",
      "Getting data for:  BRK-B\n",
      "Getting data for:  BBY\n",
      "Getting data for:  BIO\n",
      "Getting data for:  BIIB\n",
      "Getting data for:  BLK\n",
      "Getting data for:  BA\n",
      "Getting data for:  BKNG\n",
      "Getting data for:  BWA\n",
      "Getting data for:  BXP\n",
      "Getting data for:  BSX\n",
      "Getting data for:  BMY\n",
      "Getting data for:  AVGO\n",
      "Getting data for:  BR\n",
      "Getting data for:  BF-B\n",
      "Getting data for:  CHRW\n",
      "Getting data for:  COG\n",
      "Getting data for:  CDNS\n",
      "Getting data for:  CPB\n",
      "Getting data for:  COF\n",
      "Getting data for:  CAH\n",
      "Getting data for:  KMX\n",
      "Getting data for:  CCL\n",
      "Getting data for:  CARR\n",
      "Getting data for:  CAT\n",
      "Getting data for:  CBOE\n",
      "Getting data for:  CBRE\n",
      "Getting data for:  CDW\n",
      "Getting data for:  CE\n",
      "Getting data for:  CNC\n",
      "Getting data for:  CNP\n",
      "Getting data for:  CTL\n",
      "Getting data for:  CERN\n",
      "Getting data for:  CF\n",
      "Getting data for:  SCHW\n",
      "Getting data for:  CHTR\n",
      "Getting data for:  CVX\n",
      "Getting data for:  CMG\n",
      "Getting data for:  CB\n",
      "Getting data for:  CHD\n",
      "Getting data for:  CI\n",
      "Getting data for:  CINF\n",
      "Getting data for:  CTAS\n",
      "Getting data for:  CSCO\n",
      "Getting data for:  C\n",
      "Getting data for:  CFG\n",
      "Getting data for:  CTXS\n",
      "Getting data for:  CLX\n",
      "Getting data for:  CME\n",
      "Getting data for:  CMS\n",
      "Getting data for:  KO\n",
      "Getting data for:  CTSH\n",
      "Getting data for:  CL\n",
      "Getting data for:  CMCSA\n",
      "Getting data for:  CMA\n",
      "Getting data for:  CAG\n",
      "Getting data for:  CXO\n",
      "Getting data for:  COP\n",
      "Getting data for:  ED\n",
      "Getting data for:  STZ\n",
      "Getting data for:  COO\n",
      "Getting data for:  CPRT\n",
      "Getting data for:  GLW\n",
      "Getting data for:  CTVA\n",
      "Getting data for:  COST\n",
      "Getting data for:  COTY\n",
      "Getting data for:  CCI\n",
      "Getting data for:  CSX\n",
      "Getting data for:  CMI\n",
      "Getting data for:  CVS\n",
      "Getting data for:  DHI\n",
      "Getting data for:  DHR\n",
      "Getting data for:  DRI\n",
      "Getting data for:  DVA\n",
      "Getting data for:  DE\n",
      "Getting data for:  DAL\n",
      "Getting data for:  XRAY\n",
      "Getting data for:  DVN\n",
      "Getting data for:  DXCM\n",
      "Getting data for:  FANG\n",
      "Getting data for:  DLR\n",
      "Getting data for:  DFS\n",
      "Getting data for:  DISCA\n",
      "Getting data for:  DISCK\n",
      "Getting data for:  DISH\n",
      "Getting data for:  DG\n",
      "Getting data for:  DLTR\n",
      "Getting data for:  D\n",
      "Getting data for:  DPZ\n",
      "Getting data for:  DOV\n",
      "Getting data for:  DOW\n",
      "Getting data for:  DTE\n",
      "Getting data for:  DUK\n",
      "Getting data for:  DRE\n",
      "Getting data for:  DD\n",
      "Getting data for:  DXC\n",
      "Getting data for:  ETFC\n",
      "Getting data for:  EMN\n",
      "Getting data for:  ETN\n",
      "Getting data for:  EBAY\n",
      "Getting data for:  ECL\n",
      "Getting data for:  EIX\n",
      "Getting data for:  EW\n",
      "Getting data for:  EA\n",
      "Getting data for:  EMR\n",
      "Getting data for:  ETR\n",
      "Getting data for:  EOG\n",
      "Getting data for:  EFX\n",
      "Getting data for:  EQIX\n",
      "Getting data for:  EQR\n",
      "Getting data for:  ESS\n",
      "Getting data for:  EL\n",
      "Getting data for:  EVRG\n",
      "Getting data for:  ES\n",
      "Getting data for:  RE\n",
      "Getting data for:  EXC\n",
      "Getting data for:  EXPE\n",
      "Getting data for:  EXPD\n",
      "Getting data for:  EXR\n",
      "Getting data for:  XOM\n",
      "Getting data for:  FFIV\n",
      "Getting data for:  FB\n",
      "Getting data for:  FAST\n",
      "Getting data for:  FRT\n",
      "Getting data for:  FDX\n",
      "Getting data for:  FIS\n",
      "Getting data for:  FITB\n",
      "Getting data for:  FE\n",
      "Getting data for:  FRC\n",
      "Getting data for:  FISV\n",
      "Getting data for:  FLT\n",
      "Getting data for:  FLIR\n",
      "Getting data for:  FLS\n",
      "Getting data for:  FMC\n",
      "Getting data for:  F\n",
      "Getting data for:  FTNT\n",
      "Getting data for:  FTV\n",
      "Getting data for:  FBHS\n",
      "Getting data for:  FOXA\n",
      "Getting data for:  FOX\n",
      "Getting data for:  BEN\n",
      "Getting data for:  FCX\n",
      "Getting data for:  GPS\n",
      "Getting data for:  GRMN\n",
      "Getting data for:  IT\n",
      "Getting data for:  GD\n",
      "Getting data for:  GE\n",
      "Getting data for:  GIS\n",
      "Getting data for:  GM\n",
      "Getting data for:  GPC\n",
      "Getting data for:  GILD\n",
      "Getting data for:  GL\n",
      "Getting data for:  GPN\n",
      "Getting data for:  GS\n",
      "Getting data for:  GWW\n",
      "Getting data for:  HRB\n",
      "Getting data for:  HAL\n",
      "Getting data for:  HBI\n",
      "Getting data for:  HIG\n",
      "Getting data for:  HAS\n",
      "Getting data for:  HCA\n",
      "Getting data for:  PEAK\n",
      "Getting data for:  HSIC\n",
      "Getting data for:  HSY\n",
      "Getting data for:  HES\n",
      "Getting data for:  HPE\n",
      "Getting data for:  HLT\n",
      "Getting data for:  HFC\n",
      "Getting data for:  HOLX\n",
      "Getting data for:  HD\n",
      "Getting data for:  HON\n",
      "Getting data for:  HRL\n",
      "Getting data for:  HST\n",
      "Getting data for:  HWM\n",
      "Getting data for:  HPQ\n",
      "Getting data for:  HUM\n",
      "Getting data for:  HBAN\n",
      "Getting data for:  HII\n",
      "Getting data for:  IEX\n",
      "Getting data for:  IDXX\n",
      "Getting data for:  INFO\n",
      "Getting data for:  ITW\n",
      "Getting data for:  ILMN\n",
      "Getting data for:  INCY\n",
      "Getting data for:  IR\n",
      "Getting data for:  INTC\n",
      "Getting data for:  ICE\n",
      "Getting data for:  IBM\n",
      "Getting data for:  IP\n",
      "Getting data for:  IPG\n",
      "Getting data for:  IFF\n",
      "Getting data for:  INTU\n",
      "Getting data for:  ISRG\n",
      "Getting data for:  IVZ\n",
      "Getting data for:  IPGP\n",
      "Getting data for:  IQV\n",
      "Getting data for:  IRM\n",
      "Getting data for:  JKHY\n",
      "Getting data for:  J\n",
      "Getting data for:  JBHT\n",
      "Getting data for:  SJM\n",
      "Getting data for:  JNJ\n",
      "Getting data for:  JCI\n",
      "Getting data for:  JPM\n",
      "Getting data for:  JNPR\n",
      "Getting data for:  KSU\n",
      "Getting data for:  K\n",
      "Getting data for:  KEY\n",
      "Getting data for:  KEYS\n",
      "Getting data for:  KMB\n",
      "Getting data for:  KIM\n",
      "Getting data for:  KMI\n",
      "Getting data for:  KLAC\n",
      "Getting data for:  KSS\n",
      "Getting data for:  KHC\n",
      "Getting data for:  KR\n",
      "Getting data for:  LB\n",
      "Getting data for:  LHX\n",
      "Getting data for:  LH\n",
      "Getting data for:  LRCX\n",
      "Getting data for:  LW\n",
      "Getting data for:  LVS\n",
      "Getting data for:  LEG\n",
      "Getting data for:  LDOS\n",
      "Getting data for:  LEN\n",
      "Getting data for:  LLY\n",
      "Getting data for:  LNC\n",
      "Getting data for:  LIN\n",
      "Getting data for:  LYV\n",
      "Getting data for:  LKQ\n",
      "Getting data for:  LMT\n",
      "Getting data for:  L\n",
      "Getting data for:  LOW\n",
      "Getting data for:  LYB\n",
      "Getting data for:  MTB\n",
      "Getting data for:  MRO\n",
      "Getting data for:  MPC\n",
      "Getting data for:  MKTX\n",
      "Getting data for:  MAR\n",
      "Getting data for:  MMC\n",
      "Getting data for:  MLM\n",
      "Getting data for:  MAS\n",
      "Getting data for:  MA\n",
      "Getting data for:  MKC\n",
      "Getting data for:  MXIM\n",
      "Getting data for:  MCD\n",
      "Getting data for:  MCK\n",
      "Getting data for:  MDT\n",
      "Getting data for:  MRK\n",
      "Getting data for:  MET\n",
      "Getting data for:  MTD\n",
      "Getting data for:  MGM\n",
      "Getting data for:  MCHP\n",
      "Getting data for:  MU\n",
      "Getting data for:  MSFT\n",
      "Getting data for:  MAA\n",
      "Getting data for:  MHK\n",
      "Getting data for:  TAP\n",
      "Getting data for:  MDLZ\n",
      "Getting data for:  MNST\n",
      "Getting data for:  MCO\n",
      "Getting data for:  MS\n",
      "Getting data for:  MOS\n",
      "Getting data for:  MSI\n",
      "Getting data for:  MSCI\n",
      "Getting data for:  MYL\n",
      "Getting data for:  NDAQ\n",
      "Getting data for:  NOV\n",
      "Getting data for:  NTAP\n",
      "Getting data for:  NFLX\n",
      "Getting data for:  NWL\n",
      "Getting data for:  NEM\n",
      "Getting data for:  NWSA\n",
      "Getting data for:  NWS\n",
      "Getting data for:  NEE\n",
      "Getting data for:  NLSN\n",
      "Getting data for:  NKE\n",
      "Getting data for:  NI\n",
      "Getting data for:  NBL\n",
      "Getting data for:  NSC\n",
      "Getting data for:  NTRS\n",
      "Getting data for:  NOC\n",
      "Getting data for:  NLOK\n",
      "Getting data for:  NCLH\n",
      "Getting data for:  NRG\n",
      "Getting data for:  NUE\n",
      "Getting data for:  NVDA\n",
      "Getting data for:  NVR\n",
      "Getting data for:  ORLY\n",
      "Getting data for:  OXY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for:  ODFL\n",
      "Getting data for:  OMC\n",
      "Getting data for:  OKE\n",
      "Getting data for:  ORCL\n",
      "Getting data for:  OTIS\n",
      "Getting data for:  PCAR\n",
      "Getting data for:  PKG\n",
      "Getting data for:  PH\n",
      "Getting data for:  PAYX\n",
      "Getting data for:  PAYC\n",
      "Getting data for:  PYPL\n",
      "Getting data for:  PNR\n",
      "Getting data for:  PBCT\n",
      "Getting data for:  PEP\n",
      "Getting data for:  PKI\n",
      "Getting data for:  PRGO\n",
      "Getting data for:  PFE\n",
      "Getting data for:  PM\n",
      "Getting data for:  PSX\n",
      "Getting data for:  PNW\n",
      "Getting data for:  PXD\n",
      "Getting data for:  PNC\n",
      "Getting data for:  PPG\n",
      "Getting data for:  PPL\n",
      "Getting data for:  PFG\n",
      "Getting data for:  PG\n",
      "Getting data for:  PGR\n",
      "Getting data for:  PLD\n",
      "Getting data for:  PRU\n",
      "Getting data for:  PEG\n",
      "Getting data for:  PSA\n",
      "Getting data for:  PHM\n",
      "Getting data for:  PVH\n",
      "Getting data for:  QRVO\n",
      "Getting data for:  PWR\n",
      "Getting data for:  QCOM\n",
      "Getting data for:  DGX\n",
      "Getting data for:  RL\n",
      "Getting data for:  RJF\n",
      "Getting data for:  RTX\n",
      "Getting data for:  O\n",
      "Getting data for:  REG\n",
      "Getting data for:  REGN\n",
      "Getting data for:  RF\n",
      "Getting data for:  RSG\n",
      "Getting data for:  RMD\n",
      "Getting data for:  RHI\n",
      "Getting data for:  ROK\n",
      "Getting data for:  ROL\n",
      "Getting data for:  ROP\n",
      "Getting data for:  ROST\n",
      "Getting data for:  RCL\n",
      "Getting data for:  SPGI\n",
      "Getting data for:  CRM\n",
      "Getting data for:  SBAC\n",
      "Getting data for:  SLB\n",
      "Getting data for:  STX\n",
      "Getting data for:  SEE\n",
      "Getting data for:  SRE\n",
      "Getting data for:  NOW\n",
      "Getting data for:  SHW\n",
      "Getting data for:  SPG\n",
      "Getting data for:  SWKS\n",
      "Getting data for:  SLG\n",
      "Getting data for:  SNA\n",
      "Getting data for:  SO\n",
      "Getting data for:  LUV\n",
      "Getting data for:  SWK\n",
      "Getting data for:  SBUX\n",
      "Getting data for:  STT\n",
      "Getting data for:  STE\n",
      "Getting data for:  SYK\n",
      "Getting data for:  SIVB\n",
      "Getting data for:  SYF\n",
      "Getting data for:  SNPS\n",
      "Getting data for:  SYY\n",
      "Getting data for:  TMUS\n",
      "Getting data for:  TROW\n",
      "Getting data for:  TTWO\n",
      "Getting data for:  TPR\n",
      "Getting data for:  TGT\n",
      "Getting data for:  TEL\n",
      "Getting data for:  FTI\n",
      "Getting data for:  TDY\n",
      "Getting data for:  TFX\n",
      "Getting data for:  TXN\n",
      "Getting data for:  TXT\n",
      "Getting data for:  TMO\n",
      "Getting data for:  TIF\n",
      "Getting data for:  TJX\n",
      "Getting data for:  TSCO\n",
      "Getting data for:  TT\n",
      "Getting data for:  TDG\n",
      "Getting data for:  TRV\n",
      "Getting data for:  TFC\n",
      "Getting data for:  TWTR\n",
      "Getting data for:  TYL\n",
      "Getting data for:  TSN\n",
      "Getting data for:  UDR\n",
      "Getting data for:  ULTA\n",
      "Getting data for:  USB\n",
      "Getting data for:  UAA\n",
      "Getting data for:  UA\n",
      "Getting data for:  UNP\n",
      "Getting data for:  UAL\n",
      "Getting data for:  UNH\n",
      "Getting data for:  UPS\n",
      "Getting data for:  URI\n",
      "Getting data for:  UHS\n",
      "Getting data for:  UNM\n",
      "Getting data for:  VFC\n",
      "Getting data for:  VLO\n",
      "Getting data for:  VAR\n",
      "Getting data for:  VTR\n",
      "Getting data for:  VRSN\n",
      "Getting data for:  VRSK\n",
      "Getting data for:  VZ\n",
      "Getting data for:  VRTX\n",
      "Getting data for:  VIAC\n",
      "Getting data for:  V\n",
      "Getting data for:  VNO\n",
      "Getting data for:  VMC\n",
      "Getting data for:  WRB\n",
      "Getting data for:  WAB\n",
      "Getting data for:  WMT\n",
      "Getting data for:  WBA\n",
      "Getting data for:  DIS\n",
      "Getting data for:  WM\n",
      "Getting data for:  WAT\n",
      "Getting data for:  WEC\n",
      "Getting data for:  WFC\n",
      "Getting data for:  WELL\n",
      "Getting data for:  WST\n",
      "Getting data for:  WDC\n",
      "Getting data for:  WU\n",
      "Getting data for:  WRK\n",
      "Getting data for:  WY\n",
      "Getting data for:  WHR\n",
      "Getting data for:  WMB\n",
      "Getting data for:  WLTW\n",
      "Getting data for:  WYNN\n",
      "Getting data for:  XEL\n",
      "Getting data for:  XRX\n",
      "Getting data for:  XLNX\n",
      "Getting data for:  XYL\n",
      "Getting data for:  YUM\n",
      "Getting data for:  ZBRA\n",
      "Getting data for:  ZBH\n",
      "Getting data for:  ZION\n",
      "Getting data for:  ZTS\n",
      "mktCaps done\n",
      "tickers_yahoo done\n",
      "tickers_diff done\n"
     ]
    }
   ],
   "source": [
    "### Create a dictionary {ticker: market cap}\n",
    "if __name__ == \"__main__\":\n",
    "    mktCaps = get_Mcaps_yf(tickers)\n",
    "    print('mktCaps done') # check process\n",
    "    tickers_yahoo = getList(mktCaps)\n",
    "    print('tickers_yahoo done') # check process\n",
    "    tickers_diff = Diff(tickers, tickers_yahoo)\n",
    "    print('tickers_diff done') # check process\n",
    "    mktCaps_diff = get_Mcaps_yf_2(tickers_diff)\n",
    "    print('mktCaps_diff done') # check process\n",
    "    mktCaps.update(mktCaps_diff)\n",
    "    tickers_merge = getList(mktCaps) ## extract the total tickers after merge\n",
    "    tickers_diff_2 = Diff(tickers, tickers_merge) ## check if there is missing tickers\n",
    "    for ticker in tickers_diff_2:\n",
    "        mktCaps.update({ticker : 0}) ## use 0 to replace the NAN value\n",
    "    print(len(mktCaps)) # check process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the market caps for all tickers from S&P500\n",
    "print(mktCaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat the market cap and sector information into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'MktCap':pd.Series(mktCaps),'Sector':pd.Series(ticker_sector_dic)})\n",
    "df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>MktCap</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>26588786688</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AAL</td>\n",
       "      <td>7079245824</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AAP</td>\n",
       "      <td>9379105792</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1468470919168</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>162946875392</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>YUM</td>\n",
       "      <td>27473999872</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>25889542144</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>13715151872</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>ZION</td>\n",
       "      <td>5715506688</td>\n",
       "      <td>Financials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>63675342848</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker         MktCap                  Sector\n",
       "0        A    26588786688             Health Care\n",
       "1      AAL     7079245824             Industrials\n",
       "2      AAP     9379105792  Consumer Discretionary\n",
       "3     AAPL  1468470919168  Information Technology\n",
       "4     ABBV   162946875392             Health Care\n",
       "..     ...            ...                     ...\n",
       "500    YUM    27473999872  Consumer Discretionary\n",
       "501    ZBH    25889542144             Health Care\n",
       "502   ZBRA    13715151872  Information Technology\n",
       "503   ZION     5715506688              Financials\n",
       "504    ZTS    63675342848             Health Care\n",
       "\n",
       "[505 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {'index':'Ticker'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top 5 tickers in each sector based on the market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SP500_topN_Mcaps(df, n = 5):\n",
    "    \"\"\"\n",
    "    From a dataframe that contains ticker, market caps and sector, \n",
    "    this function Select top N tickers in each sector based on the market cap\n",
    "    \n",
    "    Input:\n",
    "    df: a dataframe that contains 'Ticker', 'MktCap' and 'Sector\n",
    "    n: top n tickers you want to select\n",
    "    Output:\n",
    "    df_top_MktCap: \n",
    "    \n",
    "    \"\"\"\n",
    "    df_grouped = df.groupby(['Sector'])\n",
    "    df_sort= df_grouped.apply(lambda x: x.sort_values([\"MktCap\"],ascending=False))\n",
    "    df_sort=df_sort.reset_index(drop=True).rename(columns = {'index':'Ticker'})\n",
    "    df_top_MktCap = df_sort.groupby('Sector').head(n)\n",
    "    return df_top_MktCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of top tickers: 55\n"
     ]
    }
   ],
   "source": [
    "df_new = SP500_topN_Mcaps(df, n = 5)\n",
    "print('length of top tickers:', len(df_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.sort_values([\"MktCap\"],ascending=False)\n",
    "df_new.to_excel(\"top5company.xlsx\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank these 5 top company in their own industry sector respectively based on their most important financial metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the previous document is saved as .xlsx in the same folder, import the excel\n",
    "df_new = pd.read_excel('top5company.xlsx', index_col=0)\n",
    "# if you have run the module above, the df_new can be displayed by running the code below\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Communication Services', 'Consumer Discretionary',\n",
       "       'Consumer Staples', 'Energy', 'Financials', 'Health Care',\n",
       "       'Industrials', 'Information Technology', 'Materials',\n",
       "       'Real Estate', 'Utilities'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique name of sector\n",
    "df_new.Sector.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define All the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker(df_new, sector):\n",
    "    df_sub = list(df_new[df_new['Sector'] == sector].Ticker)\n",
    "    return df_sub\n",
    "\n",
    "def get_data_balance_sheet(ticker_set, dataname):\n",
    "    df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).balance_sheet(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df_[ticker] = df[ticker]\n",
    "    return df_\n",
    "\n",
    "def get_data_cash_flow(ticker_set, dataname):\n",
    "    df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).cash_flow(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df_[ticker] = df[ticker]\n",
    "    return df_\n",
    "\n",
    "def get_rank(df, SmalltoBig = False):\n",
    "    df_transposed = df.T\n",
    "    df_transposed['Rank_last_quater'] = df_transposed.iloc[:,-1].rank(ascending = SmalltoBig)\n",
    "    df_transposed = df_transposed.sort_values(by='Rank_last_quater', ascending= True)\n",
    "    return df_transposed\n",
    "\n",
    "def get_sales_growth_each_ticker(ticker_set, dataname):\n",
    "    # df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).income_statement(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[:-1]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df['sales_growth'] = df.pct_change()\n",
    "        # df_[ticker] = df[ticker]\n",
    "        print(df)\n",
    "    return None\n",
    "\n",
    "def get_sales_growth_lastQ(ticker_set, dataname):\n",
    "    df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).income_statement(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[:-1]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df['sales_growth'] = df.pct_change()\n",
    "        df = df.tail(1).drop(columns = ticker)\n",
    "        df = df.rename(columns = {'sales_growth':ticker})\n",
    "        df.reset_index(level=0, inplace=True)\n",
    "        df.drop(columns = ['Date'])\n",
    "        df_[ticker] = df[ticker]\n",
    "    return df_\n",
    "\n",
    "\n",
    "def get_EBITDA_EV_each_ticker(ticker_set, dataname):\n",
    "    # df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).income_statement(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[:-1]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df.dropna()\n",
    "        ev = Ticker(ticker).key_stats[ticker][\"enterpriseValue\"]\n",
    "        print(\"{} has enterprice value of {}\".format(ticker,ev))\n",
    "        df['EBITDA_EV'] = df[ticker].div(ev)\n",
    "        print(\"{} has historical NormalizedEBITDA and EBITDA/EV:\".format(ticker))\n",
    "        print(df)\n",
    "        print('------------------------------')     \n",
    "    return None\n",
    "\n",
    "def get_EBITDA_EV(ticker_set, dataname):\n",
    "    df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).income_statement(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[:-1]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df.dropna()\n",
    "        ev = Ticker(ticker).key_stats[ticker][\"enterpriseValue\"]\n",
    "        df['EBITDA_EV'] = df[ticker].div(ev)\n",
    "        df = df.drop(columns = ticker)\n",
    "        df = df.rename(columns = {'EBITDA_EV':ticker})\n",
    "        df_[ticker] = df[ticker]\n",
    "    return df_\n",
    "\n",
    "def get_EBITDA_EV_lastQ(ticker_set, dataname):\n",
    "    df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).income_statement(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[:-1]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df = df.dropna()\n",
    "        ev = Ticker(ticker).key_stats[ticker][\"enterpriseValue\"]\n",
    "        df['EBITDA_EV'] = df[ticker].div(ev)\n",
    "        df = df.tail(1).drop(columns = ticker)\n",
    "        df = df.rename(columns = {'EBITDA_EV':ticker})\n",
    "        df.reset_index(level=0, inplace=True)\n",
    "        df.drop(columns = ['Date'])\n",
    "        df_[ticker] = df[ticker]\n",
    "    return df_\n",
    "\n",
    "def get_data_income_statement_deletelastrow(ticker_set, dataname):\n",
    "    df_ = pd.DataFrame()\n",
    "    for ticker in ticker_set: \n",
    "        df = Ticker(ticker).income_statement(frequency=\"q\")[['asOfDate', dataname]]\n",
    "        df = df.rename(columns = {'asOfDate':'Date', dataname:ticker})\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[:-1]\n",
    "        df.set_index('Date', inplace=True)\n",
    "        df_[ticker] = df[ticker]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Care \n",
    "### [Cash&Cash Equivalent, FCF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cash and Cash Equivalent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Data for Cash and cash equivalents\n",
      "                     JNJ           UNH           MRK           PFE  \\\n",
      "Date                                                                 \n",
      "2019-03-31  1.473400e+10  1.240700e+10  8.076000e+09  1.937000e+09   \n",
      "2019-06-30  1.437600e+10  1.374500e+10  6.659000e+09  1.784000e+09   \n",
      "2019-09-30  1.624900e+10  1.236300e+10  7.869000e+09  2.785000e+09   \n",
      "2019-12-31  1.730500e+10  1.098500e+10  9.676000e+09  1.305000e+09   \n",
      "2020-03-31  1.553000e+10  2.156900e+10  7.425000e+09  2.151000e+09   \n",
      "\n",
      "                    ABBV  \n",
      "Date                      \n",
      "2019-03-31  4.897000e+09  \n",
      "2019-06-30  5.172000e+09  \n",
      "2019-09-30  1.064800e+10  \n",
      "2019-12-31  3.992400e+10  \n",
      "2020-03-31  4.114200e+10  \n",
      "----------------------------------------------\n",
      "Rank for Cash and cash equivalents\n",
      "Date  2019-03-31 00:00:00  2019-06-30 00:00:00  2019-09-30 00:00:00  \\\n",
      "ABBV         4.897000e+09         5.172000e+09         1.064800e+10   \n",
      "UNH          1.240700e+10         1.374500e+10         1.236300e+10   \n",
      "JNJ          1.473400e+10         1.437600e+10         1.624900e+10   \n",
      "MRK          8.076000e+09         6.659000e+09         7.869000e+09   \n",
      "PFE          1.937000e+09         1.784000e+09         2.785000e+09   \n",
      "\n",
      "Date  2019-12-31 00:00:00  2020-03-31 00:00:00  Rank_last_quater  \n",
      "ABBV         3.992400e+10         4.114200e+10               1.0  \n",
      "UNH          1.098500e+10         2.156900e+10               2.0  \n",
      "JNJ          1.730500e+10         1.553000e+10               3.0  \n",
      "MRK          9.676000e+09         7.425000e+09               4.0  \n",
      "PFE          1.305000e+09         2.151000e+09               5.0  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Health Care')\n",
    "    df_cash = get_data_balance_sheet(ticker_set,'CashAndCashEquivalents')\n",
    "    print(\"Historical Data for Cash and cash equivalents\")\n",
    "    print(df_cash)\n",
    "    df_rank = get_rank(df_cash)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Rank for Cash and cash equivalents\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Free Cash Flow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Data for Free Cash Flow\n",
      "                     JNJ           UNH           MRK           PFE  \\\n",
      "Date                                                                 \n",
      "2019-03-31  2.887000e+09  2.672000e+09  7.410000e+08  1.080000e+09   \n",
      "2019-06-30  5.111000e+09  5.459000e+09  2.302000e+09  2.023000e+09   \n",
      "2019-09-30  6.782000e+09  2.706000e+09  3.267000e+09  3.848000e+09   \n",
      "2019-12-31  5.138000e+09  5.555000e+09  3.657000e+09  3.043000e+09   \n",
      "2020-03-31  2.733000e+09  2.474000e+09 -2.790000e+08  2.638000e+09   \n",
      "2020-03-31  1.976400e+10  1.619400e+10  8.947000e+09  1.155200e+10   \n",
      "\n",
      "                    ABBV  \n",
      "Date                      \n",
      "2019-03-31  2.910000e+09  \n",
      "2019-06-30  2.349000e+09  \n",
      "2019-09-30  4.401000e+09  \n",
      "2019-12-31  3.112000e+09  \n",
      "2020-03-31  3.690000e+09  \n",
      "2020-03-31  1.355200e+10  \n",
      "----------------------------------------------\n",
      "Rank for Free Cash Flow\n",
      "Date  2019-03-31 00:00:00  2019-06-30 00:00:00  2019-09-30 00:00:00  \\\n",
      "JNJ          2.887000e+09         5.111000e+09         6.782000e+09   \n",
      "UNH          2.672000e+09         5.459000e+09         2.706000e+09   \n",
      "ABBV         2.910000e+09         2.349000e+09         4.401000e+09   \n",
      "PFE          1.080000e+09         2.023000e+09         3.848000e+09   \n",
      "MRK          7.410000e+08         2.302000e+09         3.267000e+09   \n",
      "\n",
      "Date  2019-12-31 00:00:00  2020-03-31 00:00:00  2020-03-31 00:00:00  \\\n",
      "JNJ          5.138000e+09         2.733000e+09         1.976400e+10   \n",
      "UNH          5.555000e+09         2.474000e+09         1.619400e+10   \n",
      "ABBV         3.112000e+09         3.690000e+09         1.355200e+10   \n",
      "PFE          3.043000e+09         2.638000e+09         1.155200e+10   \n",
      "MRK          3.657000e+09        -2.790000e+08         8.947000e+09   \n",
      "\n",
      "Date  Rank_last_quater  \n",
      "JNJ                1.0  \n",
      "UNH                2.0  \n",
      "ABBV               3.0  \n",
      "PFE                4.0  \n",
      "MRK                5.0  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Health Care')\n",
    "    df_cash = get_data_cash_flow(ticker_set, 'FreeCashFlow')\n",
    "    print(\"Historical Data for Free Cash Flow\")\n",
    "    print(df_cash)\n",
    "    df_rank = get_rank(df_cash)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Rank for Free Cash Flow\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer Discretionary \n",
    "### [Sales growth]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Historical Total Revenue and Sales Growth Data For 5 Ticker\n",
      "                    AMZN  sales_growth\n",
      "Date                                  \n",
      "2019-03-31  5.970000e+10           NaN\n",
      "2019-06-30  6.340400e+10      0.062044\n",
      "2019-09-30  6.998100e+10      0.103732\n",
      "2019-12-31  8.743600e+10      0.249425\n",
      "2020-03-31  7.545200e+10     -0.137060\n",
      "                      HD  sales_growth\n",
      "Date                                  \n",
      "2019-04-30  2.638100e+10           NaN\n",
      "2019-07-31  3.083900e+10      0.168985\n",
      "2019-10-31  2.722300e+10     -0.117254\n",
      "2020-01-31  2.578200e+10     -0.052933\n",
      "2020-04-30  2.826000e+10      0.096114\n",
      "                     NKE  sales_growth\n",
      "Date                                  \n",
      "2019-05-31  1.018400e+10           NaN\n",
      "2019-08-31  1.066000e+10      0.046740\n",
      "2019-08-31  3.982900e+10      2.736304\n",
      "2019-11-30  1.032600e+10     -0.740742\n",
      "2020-02-29  1.010400e+10     -0.021499\n",
      "                     MCD  sales_growth\n",
      "Date                                  \n",
      "2019-03-31  4.955600e+09           NaN\n",
      "2019-06-30  5.341300e+09      0.077831\n",
      "2019-09-30  5.430600e+09      0.016719\n",
      "2019-12-31  5.349000e+09     -0.015026\n",
      "2020-03-31  4.714400e+09     -0.118639\n",
      "                     LOW  sales_growth\n",
      "Date                                  \n",
      "2019-04-30  1.774100e+10           NaN\n",
      "2019-07-31  2.099200e+10      0.183248\n",
      "2019-10-31  1.738800e+10     -0.171684\n",
      "2020-01-31  1.602700e+10     -0.078272\n",
      "2020-04-30  1.967500e+10      0.227616\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new,'Consumer Discretionary')\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"Historical Total Revenue and Sales Growth Data For 5 Ticker\")\n",
    "    get_sales_growth_each_ticker(ticker_set, 'TotalRevenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Rank for Sales Growth in Last Quarter\n",
      "      sales_growth  Rank_last_quater\n",
      "LOW       0.227616               1.0\n",
      "HD        0.096114               2.0\n",
      "NKE      -0.021499               3.0\n",
      "MCD      -0.118639               4.0\n",
      "AMZN     -0.137060               5.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new,'Consumer Discretionary')\n",
    "    df_sales_g = get_sales_growth_lastQ(ticker_set, 'TotalRevenue')\n",
    "    df_rank = get_rank(df_sales_g)\n",
    "    df_rank = df_rank.rename(columns = {0:'sales_growth'})\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"Rank for Sales Growth in Last Quarter\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy\n",
    "### EBITDA/EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Calculate the EBITDA_EV -------\n",
      "XOM has enterprice value of 254308728832\n",
      "XOM has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     XOM  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  9.041000e+09   0.035551\n",
      "2019-06-30  9.479000e+09   0.037274\n",
      "2019-09-30  9.826000e+09   0.038638\n",
      "2019-12-31  1.153800e+10   0.045370\n",
      "2020-03-31  5.810000e+09   0.022846\n",
      "------------------------------\n",
      "CVX has enterprice value of 197283151872\n",
      "CVX has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     CVX  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  8.276000e+09   0.041950\n",
      "2019-06-30  1.046700e+10   0.053056\n",
      "2019-09-30  8.607000e+09   0.043628\n",
      "2019-12-31  8.202000e+09   0.041575\n",
      "2020-03-31  8.595000e+09   0.043567\n",
      "------------------------------\n",
      "COP has enterprice value of 53748154368\n",
      "COP has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     COP  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  4.462000e+09   0.083017\n",
      "2019-06-30  3.660000e+09   0.068095\n",
      "2019-09-30  3.461000e+09   0.064393\n",
      "2019-12-31  2.665000e+09   0.049583\n",
      "2020-03-31  5.230000e+08   0.009731\n",
      "------------------------------\n",
      "KMI has enterprice value of 70678052864\n",
      "KMI has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     KMI  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  1.792000e+09   0.025354\n",
      "2019-06-30  1.697000e+09   0.024010\n",
      "2019-09-30  1.690000e+09   0.023911\n",
      "2019-12-31  1.256000e+09   0.017771\n",
      "2020-03-31  1.741000e+09   0.024633\n",
      "------------------------------\n",
      "PSX has enterprice value of 47746486272\n",
      "PSX has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     PSX  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  7.950000e+08   0.016650\n",
      "2019-06-30  2.289000e+09   0.047941\n",
      "2019-09-30  2.214000e+09   0.046370\n",
      "2019-12-31  1.525000e+09   0.031940\n",
      "2020-03-31  9.800000e+08   0.020525\n",
      "------------------------------\n",
      "                 XOM       CVX       COP       KMI       PSX\n",
      "Date                                                        \n",
      "2019-03-31  0.035551  0.041950  0.083017  0.025354  0.016650\n",
      "2019-06-30  0.037274  0.053056  0.068095  0.024010  0.047941\n",
      "2019-09-30  0.038638  0.043628  0.064393  0.023911  0.046370\n",
      "2019-12-31  0.045370  0.041575  0.049583  0.017771  0.031940\n",
      "2020-03-31  0.022846  0.043567  0.009731  0.024633  0.020525\n",
      "----------------------------------------------\n",
      "Rank for EBITDA_EV\n",
      "Date  2019-03-31 00:00:00  2019-06-30 00:00:00  2019-09-30 00:00:00  \\\n",
      "CVX              0.041950             0.053056             0.043628   \n",
      "KMI              0.025354             0.024010             0.023911   \n",
      "XOM              0.035551             0.037274             0.038638   \n",
      "PSX              0.016650             0.047941             0.046370   \n",
      "COP              0.083017             0.068095             0.064393   \n",
      "\n",
      "Date  2019-12-31 00:00:00  2020-03-31 00:00:00  Rank_last_quater  \n",
      "CVX              0.041575             0.043567               1.0  \n",
      "KMI              0.017771             0.024633               2.0  \n",
      "XOM              0.045370             0.022846               3.0  \n",
      "PSX              0.031940             0.020525               4.0  \n",
      "COP              0.049583             0.009731               5.0  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Energy')\n",
    "    print('---------- Calculate the EBITDA_EV -------')\n",
    "    get_EBITDA_EV_each_ticker(ticker_set,'NormalizedEBITDA')\n",
    "    df = get_EBITDA_EV(ticker_set, 'NormalizedEBITDA')\n",
    "    print(df)\n",
    "    df_rank = get_rank(df)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Rank for EBITDA_EV\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer Staples\n",
    "### EBITDA/EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Calculate the EBITDA_EV -------\n",
      "WMT has enterprice value of 400961208320\n",
      "WMT has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     WMT  EBITDA_EV\n",
      "Date                               \n",
      "2019-04-30  8.544000e+09   0.021309\n",
      "2019-07-31  8.276000e+09   0.020640\n",
      "2019-10-31  7.729000e+09   0.019276\n",
      "2020-01-31  9.153000e+09   0.022828\n",
      "2020-04-30  8.779000e+09   0.021895\n",
      "------------------------------\n",
      "PG has enterprice value of 310413787136\n",
      "PG has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                      PG  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  4.120000e+09   0.013273\n",
      "2019-06-30 -4.134000e+09  -0.013318\n",
      "2019-09-30  5.174000e+09   0.016668\n",
      "2019-12-31  5.309000e+09   0.017103\n",
      "2020-03-31  4.397000e+09   0.014165\n",
      "------------------------------\n",
      "KO has enterprice value of 230261047296\n",
      "KO has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                      KO  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  2.639000e+09   0.011461\n",
      "2019-06-30  3.612000e+09   0.015687\n",
      "2019-09-30  3.685000e+09   0.016004\n",
      "2019-12-31  3.055000e+09   0.013268\n",
      "2020-03-31  3.570000e+09   0.015504\n",
      "------------------------------\n",
      "PEP has enterprice value of 209077551104\n",
      "PEP has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                     PEP  EBITDA_EV\n",
      "Date                               \n",
      "2019-03-31  2.633000e+09   0.012593\n",
      "2019-06-30  3.386000e+09   0.016195\n",
      "2019-09-30  3.509000e+09   0.016783\n",
      "2019-12-31  3.351000e+09   0.016028\n",
      "2020-03-31  2.534000e+09   0.012120\n",
      "------------------------------\n",
      "COST has enterprice value of 133021130752\n",
      "COST has historical NormalizedEBITDA and EBITDA/EV:\n",
      "                    COST  EBITDA_EV\n",
      "Date                               \n",
      "2019-05-31  1.491000e+09   0.011209\n",
      "2019-08-31  1.989000e+09   0.014953\n",
      "2019-11-30  1.469000e+09   0.011043\n",
      "2020-02-29  1.692000e+09   0.012720\n",
      "2020-05-31  1.577000e+09   0.011855\n",
      "------------------------------\n",
      "----------------------------------------------\n",
      "-------------------------------------\n",
      "Show the data for last quater\n",
      "        WMT        PG        KO      PEP      COST\n",
      "0  0.021895  0.014165  0.015504  0.01212  0.011855\n",
      "-------------------------------------\n",
      "Rank for EBITDA_EV in Last Quarter\n",
      "      EBITDA_EV  Rank_last_quater\n",
      "WMT    0.021895               1.0\n",
      "KO     0.015504               2.0\n",
      "PG     0.014165               3.0\n",
      "PEP    0.012120               4.0\n",
      "COST   0.011855               5.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Consumer Staples')\n",
    "    print('---------- Calculate the EBITDA_EV -------')\n",
    "    get_EBITDA_EV_each_ticker(ticker_set,'NormalizedEBITDA')\n",
    "    print(\"----------------------------------------------\")\n",
    "    df = get_EBITDA_EV_lastQ(ticker_set,'NormalizedEBITDA')\n",
    "    print(\"-------------------------------------\")\n",
    "    print('Show the data for last quater')\n",
    "    print(df)\n",
    "    df_rank = get_rank(df)\n",
    "    df_rank = df_rank.rename(columns = {0:'EBITDA_EV'})\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"Rank for EBITDA_EV in Last Quarter\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Utilities': \n",
    "### Debt-To-Equity (D/E) Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     NEE             D           DUK            SO  \\\n",
      "Date                                                                 \n",
      "2019-03-31  3.784000e+10  2.759900e+10  4.504500e+10  3.097800e+10   \n",
      "2019-06-30  3.842600e+10  2.838100e+10  4.533200e+10  3.142200e+10   \n",
      "2019-09-30  4.017400e+10  2.995700e+10  4.740700e+10  3.208200e+10   \n",
      "2019-12-31  4.136000e+10  3.403300e+10  4.795100e+10  3.205000e+10   \n",
      "2020-03-31  4.087500e+10  3.275200e+10  4.808300e+10  3.220700e+10   \n",
      "\n",
      "                     AEP  \n",
      "Date                      \n",
      "2019-03-31  1.922850e+10  \n",
      "2019-06-30  1.942320e+10  \n",
      "2019-09-30  1.999770e+10  \n",
      "2019-12-31  1.991320e+10  \n",
      "2020-03-31  2.000770e+10  \n",
      "                     NEE             D           DUK            SO  \\\n",
      "Date                                                                 \n",
      "2019-03-31  4.021300e+10  4.277100e+10  6.069900e+10  4.596900e+10   \n",
      "2019-06-30  4.171700e+10  4.196300e+10  6.233500e+10  4.615800e+10   \n",
      "2019-09-30  4.178700e+10  4.127300e+10  6.183900e+10  4.778300e+10   \n",
      "2019-12-31  4.258300e+10  3.789700e+10  6.269300e+10  4.868600e+10   \n",
      "2020-03-31  4.720600e+10  3.972400e+10  6.583500e+10  4.959400e+10   \n",
      "\n",
      "                     AEP  \n",
      "Date                      \n",
      "2019-03-31  2.737310e+10  \n",
      "2019-06-30  2.873520e+10  \n",
      "2019-09-30  2.942110e+10  \n",
      "2019-12-31  3.053250e+10  \n",
      "2020-03-31  3.332740e+10  \n",
      "                 NEE         D       DUK        SO       AEP\n",
      "Date                                                        \n",
      "2019-03-31  1.062711  1.549730  1.347519  1.483924  1.423569\n",
      "2019-06-30  1.085645  1.478560  1.375077  1.468971  1.479427\n",
      "2019-09-30  1.040150  1.377741  1.304428  1.489402  1.471224\n",
      "2019-12-31  1.029570  1.113537  1.307439  1.519064  1.533279\n",
      "2020-03-31  1.154887  1.212872  1.369195  1.539852  1.665729\n",
      "----------------------------------------------\n",
      "Rank for Debt to Equity\n",
      "Date  2019-03-31 00:00:00  2019-06-30 00:00:00  2019-09-30 00:00:00  \\\n",
      "NEE              1.062711             1.085645             1.040150   \n",
      "D                1.549730             1.478560             1.377741   \n",
      "DUK              1.347519             1.375077             1.304428   \n",
      "SO               1.483924             1.468971             1.489402   \n",
      "AEP              1.423569             1.479427             1.471224   \n",
      "\n",
      "Date  2019-12-31 00:00:00  2020-03-31 00:00:00  Rank_last_quater  \n",
      "NEE              1.029570             1.154887               1.0  \n",
      "D                1.113537             1.212872               2.0  \n",
      "DUK              1.307439             1.369195               3.0  \n",
      "SO               1.519064             1.539852               4.0  \n",
      "AEP              1.533279             1.665729               5.0  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Utilities')\n",
    "    df_equity = get_data_balance_sheet(ticker_set, 'TotalEquityGrossMinorityInterest')\n",
    "    df_debt = get_data_balance_sheet(ticker_set, 'TotalDebt')\n",
    "    df_DtoE = df_debt / df_equity\n",
    "    print(df_equity)\n",
    "    print(df_debt)\n",
    "    print(df_DtoE)\n",
    "    df_rank = get_rank(df_DtoE, SmalltoBig = True)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Rank for Debt to Equity\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Financials': \n",
    "### Return on Equity (ROE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Historical Data of Share Holder Equity\n",
      "                   BRK-B           JPM           BAC           WFC  \\\n",
      "Date                                                                 \n",
      "2019-03-31  3.688770e+11  2.598370e+11  2.670100e+11  1.978320e+11   \n",
      "2019-06-30  3.825440e+11  2.632150e+11  2.714080e+11  1.990420e+11   \n",
      "2019-09-30  3.976090e+11  2.643480e+11  2.683870e+11  1.933040e+11   \n",
      "2019-12-31  4.247910e+11  2.613300e+11  2.648100e+11  1.871460e+11   \n",
      "2020-03-31  3.715650e+11  2.612620e+11  2.649180e+11  1.827180e+11   \n",
      "\n",
      "                       C  \n",
      "Date                      \n",
      "2019-03-31  1.962520e+11  \n",
      "2019-06-30  1.973590e+11  \n",
      "2019-09-30  1.963730e+11  \n",
      "2019-12-31  1.932420e+11  \n",
      "2020-03-31  1.923310e+11  \n",
      "----------------------------------------------\n",
      "Historical Data of Net Income\n",
      "                   BRK-B           JPM           BAC           WFC  \\\n",
      "Date                                                                 \n",
      "2019-03-31  2.166100e+10  9.179000e+09  7.311000e+09  5.860000e+09   \n",
      "2019-06-30  1.407300e+10  9.652000e+09  7.348000e+09  6.206000e+09   \n",
      "2019-09-30  1.652400e+10  9.080000e+09  5.777000e+09  4.610000e+09   \n",
      "2019-12-31  2.915900e+10  8.520000e+09  6.994000e+09  2.873000e+09   \n",
      "2020-03-31 -4.974600e+10  2.865000e+09  4.010000e+09  6.530000e+08   \n",
      "\n",
      "                       C  \n",
      "Date                      \n",
      "2019-03-31  4.710000e+09  \n",
      "2019-06-30  4.799000e+09  \n",
      "2019-09-30  4.913000e+09  \n",
      "2019-12-31  4.979000e+09  \n",
      "2020-03-31  2.522000e+09  \n",
      "----------------------------------------------\n",
      "Historical Data of Return on Equity\n",
      "               BRK-B       JPM       BAC       WFC         C\n",
      "Date                                                        \n",
      "2019-03-31  0.058721  0.035326  0.027381  0.029621  0.024000\n",
      "2019-06-30  0.036788  0.036670  0.027074  0.031179  0.024316\n",
      "2019-09-30  0.041558  0.034349  0.021525  0.023848  0.025019\n",
      "2019-12-31  0.068643  0.032602  0.026411  0.015352  0.025766\n",
      "2020-03-31 -0.133882  0.010966  0.015137  0.003574  0.013113\n",
      "----------------------------------------------\n",
      "Rank for Return on Equity: The higher the better\n",
      "Date   2019-03-31 00:00:00  2019-06-30 00:00:00  2019-09-30 00:00:00  \\\n",
      "BAC               0.027381             0.027074             0.021525   \n",
      "C                 0.024000             0.024316             0.025019   \n",
      "JPM               0.035326             0.036670             0.034349   \n",
      "WFC               0.029621             0.031179             0.023848   \n",
      "BRK-B             0.058721             0.036788             0.041558   \n",
      "\n",
      "Date   2019-12-31 00:00:00  2020-03-31 00:00:00  Rank_last_quater  \n",
      "BAC               0.026411             0.015137               1.0  \n",
      "C                 0.025766             0.013113               2.0  \n",
      "JPM               0.032602             0.010966               3.0  \n",
      "WFC               0.015352             0.003574               4.0  \n",
      "BRK-B             0.068643            -0.133882               5.0  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Financials')\n",
    "    df_equity = get_data_balance_sheet(ticker_set, 'StockholdersEquity')\n",
    "    df_income = get_data_cash_flow(ticker_set, 'NetIncome')\n",
    "    df_income = df_income[:-1]\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Historical Data of Share Holder Equity\")\n",
    "    print(df_equity)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Historical Data of Net Income\")\n",
    "    print(df_income)\n",
    "    df_ItoE = df_income / df_equity\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Historical Data of Return on Equity\")\n",
    "    print(df_ItoE)\n",
    "    df_rank = get_rank(df_ItoE, SmalltoBig = False)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Rank for Return on Equity: The higher the better\")\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Communication Services': \n",
    "### P/E ratio | EPS growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPS growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Basic EPS data\n",
      "            GOOGL   GOOG    FB    VZ     T\n",
      "Date                                      \n",
      "2019-03-31   9.58   9.58  0.85  1.22  0.56\n",
      "2019-06-30  14.33  14.33  0.92  0.95  0.51\n",
      "2019-09-30  10.20  10.20  2.13  1.26  0.50\n",
      "2019-12-31  15.49  15.49  2.58  1.23  0.33\n",
      "2020-03-31   9.96   9.96  1.72  1.00  0.63\n",
      "-------------------------------------\n",
      "Historical Basic EPS growth data\n",
      "               GOOGL      GOOG        FB        VZ         T\n",
      "Date                                                        \n",
      "2019-03-31       NaN       NaN       NaN       NaN       NaN\n",
      "2019-06-30  0.495825  0.495825  0.082353 -0.221311 -0.089286\n",
      "2019-09-30 -0.288207 -0.288207  1.315217  0.326316 -0.019608\n",
      "2019-12-31  0.518627  0.518627  0.211268 -0.023810 -0.340000\n",
      "2020-03-31 -0.357005 -0.357005 -0.333333 -0.186992  0.909091\n",
      "-------------------------------------\n",
      "Rank for Basic EPS growth in Last Quarter: the higher growth rate the better\n",
      "Date   2019-03-31 00:00:00  2019-06-30 00:00:00  2019-09-30 00:00:00  \\\n",
      "T                      NaN            -0.089286            -0.019608   \n",
      "VZ                     NaN            -0.221311             0.326316   \n",
      "FB                     NaN             0.082353             1.315217   \n",
      "GOOGL                  NaN             0.495825            -0.288207   \n",
      "GOOG                   NaN             0.495825            -0.288207   \n",
      "\n",
      "Date   2019-12-31 00:00:00  2020-03-31 00:00:00  Rank_last_quater  \n",
      "T                -0.340000             0.909091               1.0  \n",
      "VZ               -0.023810            -0.186992               2.0  \n",
      "FB                0.211268            -0.333333               3.0  \n",
      "GOOGL             0.518627            -0.357005               4.5  \n",
      "GOOG              0.518627            -0.357005               4.5  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ticker_set = get_ticker(df_new, 'Communication Services')\n",
    "    df = get_data_income_statement_deletelastrow(ticker_set, 'BasicEPS')\n",
    "    print('Historical Basic EPS data')\n",
    "    print(df)\n",
    "    df_change = df.pct_change()\n",
    "    print(\"-------------------------------------\")\n",
    "    print('Historical Basic EPS growth data')\n",
    "    print(df_change)\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"Rank for Basic EPS growth in Last Quarter: the higher growth rate the better\")\n",
    "    df_rank = get_rank(df_change, SmalltoBig = False)\n",
    "    print(df_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
