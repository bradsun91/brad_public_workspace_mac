{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "np.set_printoptions(suppress=True)# 关掉科学计数法\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "# 一次性merge多个pct_chg\n",
    "from functools import reduce\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from statsmodels import regression\n",
    "\n",
    "# import tushare as ts\n",
    "import time, urllib\n",
    "# ts.set_token('8ef5ec61cdd848715c57c11d58dd71da1271f76b2420d2bac8aef123')\n",
    "# pro = ts.pro_api('8ef5ec61cdd848715c57c11d58dd71da1271f76b2420d2bac8aef123')\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=False, rc=None)\n",
    "\n",
    "\n",
    "# from plotly.graph_objs import Scatter,Layout\n",
    "# import plotly\n",
    "# import plotly.offline as py\n",
    "# import numpy as np\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# #setting offilne\n",
    "# plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TechnicalIndicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechnicalIndicators(object):\n",
    "\n",
    "    def EMA(df, n, price_col): # n = 5\n",
    "        \"\"\"\n",
    "        Exponential Moving Average\n",
    "        rationale CHECKED, code CHECKED, updated.\n",
    "\n",
    "        params:\n",
    "            df: pd dataframe\n",
    "            n: number of days = 5\n",
    "        \"\"\"\n",
    "        EMA = df[price_col].ewm(span=n, min_periods=n - 1).mean().rename('EMA_' + str(n))\n",
    "        return EMA\n",
    "\n",
    "    def OBV(df, n, price_col, vol_col): # n = 5\n",
    "        \"\"\"On-balance Volume\n",
    "\n",
    "        On Balance Volume (OBV) measures buying and selling pressure as a cumulative indicator that adds \n",
    "        volume on up days and subtracts volume on down days. OBV was developed by Joe Granville and introduced \n",
    "        in his 1963 book, Granville's New Key to Stock Market Profits. It was one of the first indicators to \n",
    "        measure positive and negative volume flow. Chartists can look for divergences between OBV and price \n",
    "        to predict price movements or use OBV to confirm price trends.\n",
    "\n",
    "        http://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:on_balance_volume_obv\n",
    "        \"\"\"\n",
    "        df = df.reset_index()\n",
    "        i = 0\n",
    "        OBV = [0]\n",
    "        while i < df.index[-1]:\n",
    "            if df.at[i + 1, price_col] - df.at[i, price_col] > 0:\n",
    "                OBV.append(df.at[i + 1, vol_col])\n",
    "            if df.at[i + 1, price_col] - df.at[i, price_col] == 0:\n",
    "                OBV.append(0)\n",
    "            if df.at[i + 1, price_col] - df.at[i, price_col] < 0:\n",
    "                OBV.append(-df.at[i + 1, vol_col])\n",
    "            i = i + 1\n",
    "        OBV = pd.Series(OBV)\n",
    "        OBV_ma = pd.Series(OBV.rolling(window=n).mean(), name = 'OBV_' + str(n))\n",
    "        return OBV_ma\n",
    "\n",
    "    # Rationale checked\n",
    "    def MFI(df, n, hi_col, lo_col, price_col, vol_col): # n = 14\n",
    "        \"\"\"Money Flow Index and Ratio, updated.\n",
    "        http://stockcharts.com/docs/doku.php?id=scans:indicators#money_flow_index_mfi\n",
    "\n",
    "        \"\"\"\n",
    "        df = df.reset_index()\n",
    "        PP = (df[hi_col] + df[lo_col] + df[price_col]) / 3\n",
    "        i  = 0\n",
    "        PosMF = [0]\n",
    "        while i < df.index[-1]:\n",
    "            if PP[i + 1] > PP[i]:\n",
    "                PosMF.append(PP[i + 1] * df.at[i + 1, vol_col])\n",
    "            else:\n",
    "                PosMF.append(0)\n",
    "            i = i + 1\n",
    "        PosMF = pd.Series(PosMF)\n",
    "        TotMF = PP * df[vol_col]\n",
    "        MFR   = pd.Series(PosMF / TotMF)\n",
    "        MFI   = pd.Series(MFR.rolling(window = n, center = False).mean(), name = 'MFI_' + str(n))\n",
    "        df    = df.join(MFI).set_index(\"index\")\n",
    "        return df[\"MFI_\" + str(n)]\n",
    "\n",
    "    # Done\n",
    "    # Rationale checked\n",
    "    def RSI(df, n, hi_col, lo_col): # n = 14\n",
    "        \"\"\"\n",
    "        Relative Strength Index, updated.\n",
    "        Conventional parameters: n = 14, 0.3 and 0.7 are two conventional thresholds\n",
    "        \"\"\"\n",
    "        df = df.reset_index()\n",
    "        i = 0\n",
    "        UpI = [0]\n",
    "        DoI = [0]\n",
    "        while i + 1 <= df.index[-1]:\n",
    "            UpMove = df.at[i + 1, hi_col] - df.at[i, hi_col]\n",
    "            DoMove = df.at[i, lo_col] - df.at[i + 1, lo_col]\n",
    "            if UpMove > DoMove and UpMove > 0:\n",
    "                UpD = UpMove\n",
    "            else: UpD = 0\n",
    "            UpI.append(UpD)\n",
    "            if DoMove > UpMove and DoMove > 0:\n",
    "                DoD = DoMove\n",
    "            else: DoD = 0\n",
    "            DoI.append(DoD)\n",
    "            i = i + 1\n",
    "        UpI   = pd.Series(UpI)\n",
    "        DoI   = pd.Series(DoI)\n",
    "        PosDI = UpI.ewm(span = n, min_periods = n - 1).mean()\n",
    "        NegDI = DoI.ewm(span = n, min_periods = n - 1).mean()\n",
    "        RSI   = pd.Series(PosDI / (PosDI + NegDI), name = 'RSI_' + str(n))\n",
    "        df    = df.join(RSI).set_index(\"index\")\n",
    "        return df[\"RSI_\" + str(n)]\n",
    "\n",
    "    def BIAS(df, n, price_col):\n",
    "        BIAS = df[price_col]-df[price_col].rolling(window=n).mean().rename('BIAS_'+str(n))\n",
    "        return BIAS\n",
    "\n",
    "    def MACD(df, n_fast, n_slow, n_macd, price_col): # n_fast = 12, n_slow = 26\n",
    "        \"\"\"\n",
    "        http://stockcharts.com/docs/doku.php?id=scans:indicators\n",
    "        MACD, MACD Signal and MACD difference, rationale CHECKED, code CHECKED, updated\n",
    "        # Conventional look-back window for calculating MACDsign is 9\n",
    "        \"\"\"\n",
    "        EMAfast = df[price_col].ewm(span = n_fast, min_periods = n_fast - 1).mean()\n",
    "        EMAslow = df[price_col].ewm(span = n_slow, min_periods = n_slow - 1).mean()\n",
    "        MACD = pd.Series(EMAfast - EMAslow, name = 'MACD_' + str(n_fast) + '_' + str(n_slow))\n",
    "        MACDsign = MACD.ewm(span = n_macd, min_periods = n_macd-1).mean().rename('MACDsign_' + str(n_fast) + '_' + str(n_slow))\n",
    "        MACDdiff = pd.Series(MACD - MACDsign, name = 'MACDdiff_' + str(n_fast) + '_' + str(n_slow))\n",
    "        df['MACD_Diff'] = MACD\n",
    "        df['MACD_Diff_EMA'] = MACDsign\n",
    "        df['MACD'] = MACDdiff\n",
    "        df['SIGNAL_STATUS'] = df['MACD'].apply(lambda x: \"多头状态\" if x>0 else (\"空头状态\" if x<0 else \"无信号状态\"))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeriesToolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData(object):\n",
    "    \n",
    "    def get_date_price_code_df(path, ticker_list, date_col, price_col, code_col):\n",
    "        # for etf data cols are 'date', 'close', 'code'\n",
    "        ticker_df_list = []\n",
    "#         print(ticker_list)\n",
    "        for ticker in ticker_list:\n",
    "            print(ticker)\n",
    "            try:\n",
    "#                 print(\"get thru\")\n",
    "                \n",
    "                ticker_df = pd.read_csv(path+ticker+\".csv\")\n",
    "                ticker_df[code_col] = ticker_df[code_col].astype(str)\n",
    "                ticker_df = ticker_df.sort_values(date_col)\n",
    "                ticker_df = ticker_df[[date_col, price_col, code_col]]\n",
    "#                 print(ticker_df)\n",
    "                ticker_df_list.append(ticker_df)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        try:\n",
    "            tickers_data_concated = pd.concat(ticker_df_list)\n",
    "            tickers_data_concated.reset_index(inplace=True)\n",
    "            del tickers_data_concated['index']  \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "#         print(tickers_data_concated)\n",
    "        return tickers_data_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesToolbox(object):\n",
    "        \n",
    "    def make_numeric_signals(series):\n",
    "        for item in series:\n",
    "            if item ==\"多\":\n",
    "                return 1\n",
    "            elif item ==\"空\":\n",
    "                return -1\n",
    "            else:\n",
    "                return 0 \n",
    "            \n",
    "    def merge_weights_and_signal(df_actions,\n",
    "                                 df_wts,\n",
    "                                 path,\n",
    "                                 code_col,\n",
    "                                 date_col,\n",
    "                                 price_col,\n",
    "                                 tgt_wts_mutiplier,\n",
    "                                 account_value):\n",
    "        if df_actions.empty:\n",
    "            print(\"There's no data in df_actions. No actional signals for today!\")\n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            # 合并仓位数据和信号数据\n",
    "            df_actions_with_weights = df_wts.merge(df_actions, on =code_col)\n",
    "\n",
    "            # 仓位太小，创建2倍仓位信息, e.g. tgt_wts_mutiplier = 2\n",
    "            df_actions_with_weights['weight_enlarged'] = df_actions_with_weights['weight']*tgt_wts_mutiplier\n",
    "    #         print(df_actions_with_weights)\n",
    "            # 提取下一日要操作的tickers\n",
    "            tickers = list(df_actions_with_weights[code_col])\n",
    "    #         print(tickers)\n",
    "            # 得到这些tickers的收盘价数据\n",
    "    #         print(tickers)\n",
    "            tickers_closes = GetData.get_date_price_code_df(path,\n",
    "                                                             tickers,\n",
    "                                                             date_col, \n",
    "                                                             price_col, \n",
    "                                                             code_col)\n",
    "    #         print(tickers_closes)\n",
    "            # 创建今日date信息\n",
    "            last_date = tickers_closes[date_col].values[-1]\n",
    "    #         print(last_date)\n",
    "            # 提取最近一天的tickers的收盘价数据\n",
    "            tickers_closes_last_date = tickers_closes[tickers_closes[date_col] == last_date]\n",
    "\n",
    "            # 创建最终的信号-仓位指示信息\n",
    "            df_actions_with_weights = df_actions_with_weights.merge(tickers_closes_last_date, on = [date_col,\n",
    "                                                                                                    code_col])\n",
    "            df_actions_with_weights['tgt_shares'] = account_value*\\\n",
    "                                                    df_actions_with_weights['weight_enlarged']/\\\n",
    "                                                    df_actions_with_weights[price_col]\n",
    "            return df_actions_with_weights\n",
    "     \n",
    "    def merge_current_pos_with_target_pos(path, cur_positions, tgt_last_macd_signals):\n",
    "        tgt_last_macd_signals['TYPE'] = \"TARGET\"\n",
    "        # the following variables should be assigned first\n",
    "        cur_pos_macd = MACDSignals(path, \n",
    "                        cur_positions, \n",
    "                        date_col, \n",
    "                        code_col, \n",
    "                        price_col, \n",
    "                        n_fast, \n",
    "                        n_slow, \n",
    "                        n_macd, \n",
    "                        ticker_type)\n",
    "        cur_pos_macd_signals, \\\n",
    "        cur_pos_last_macd_signals, \\\n",
    "        cur_pos_df_actions = cur_pos_macd.calc_macd_signals()\n",
    "        cur_pos_last_macd_signals['TYPE'] = 'CUR_POS'\n",
    "        tgt_cur_macd_signal_df = cur_pos_last_macd_signals.merge(tgt_last_macd_signals, on = [date_col,code_col], how = 'outer')\n",
    "        return tgt_cur_macd_signal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlotToolBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotToolbox(object):\n",
    "    \n",
    "    def pie_graph(values, labels, pie_length, pie_width, title_name):\n",
    "        # draw pie graph\n",
    "        plt.figure(1, figsize = (pie_length, pie_width))\n",
    "        plt.axes(aspect=1)\n",
    "        plt.pie(x=values, labels=labels, autopct='%3.1f %%')\n",
    "        plt.title(title_name, fontsize = 15)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def plot_macd_signals(ticker, macd_signals, tail_num):\n",
    "        ticker_macd_signals = macd_signals[macd_signals[code_col]==ticker]\n",
    "        ticker_macd_signals.set_index(date_col, inplace = True)\n",
    "        ticker_macd_signals[[code_col,\"MACD\"]].tail(tail_num).plot(figsize = (15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在分析环境里，筛选出tickers，然后使用MACD_signals\n",
    "\n",
    "class MACDSignals(object):\n",
    "    \n",
    "    def __init__(self, stocks_path, tickers, date_col, code_col, price_col, n_fast, n_slow, n_macd, ticker_type):\n",
    "        self.path = stocks_path\n",
    "        self.tickers = tickers\n",
    "        self.date_col = date_col\n",
    "        self.code_col = code_col\n",
    "        self.price_col = price_col\n",
    "        self.n_fast = n_fast\n",
    "        self.n_slow = n_slow\n",
    "        self.n_macd = n_macd\n",
    "        self.ticker_type = ticker_type\n",
    "        self.mkt_data = self.get_mkt_data_df()\n",
    "\n",
    "    def get_mkt_data_df(self):\n",
    "    # e.g. ch_db_path = \"/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/data/CH_database/\"\n",
    "        csv_path = self.path+\"*.csv\"\n",
    "        files = glob.glob(csv_path)\n",
    "        ticker_df_list = []\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                ticker_df = pd.read_csv(self.path+ticker+\".csv\")\n",
    "                ticker_df[self.code_col] = ticker_df[self.code_col].astype(str)\n",
    "                ticker_df = ticker_df.sort_values(self.date_col)\n",
    "                ticker_df_list.append(ticker_df)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        try:\n",
    "            tickers_data_concated = pd.concat(ticker_df_list)\n",
    "            tickers_data_concated.reset_index(inplace=True)\n",
    "            del tickers_data_concated['index']  \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return tickers_data_concated\n",
    "    \n",
    "\n",
    "    def calc_macd_signals(self):\n",
    "        tickers_data_concated = self.mkt_data\n",
    "#         print(tickers_data_concated)\n",
    "        signal_record = []\n",
    "        signal_data = []\n",
    "        if len(self.tickers)!=1:\n",
    "            for ticker in self.tickers:\n",
    "                try:\n",
    "                    if self.ticker_type == \"float\":\n",
    "                        single_ticker_df = tickers_data_concated[tickers_data_concated[self.code_col]==float(ticker)]\n",
    "                    elif self.ticker_type == \"string\":\n",
    "                        single_ticker_df = tickers_data_concated[tickers_data_concated[self.code_col]==ticker]\n",
    "                        \n",
    "                    signal_df = TechnicalIndicators.MACD(single_ticker_df, self.n_fast, self.n_slow, self.n_macd, self.price_col)\n",
    "                    \n",
    "                    signal_data.append(signal_df)\n",
    "                except:\n",
    "                    pass\n",
    "            signal_data_df = pd.concat(signal_data)\n",
    "        else:\n",
    "            try:                \n",
    "                signal_df = TechnicalIndicators.MACD(single_ticker_df, self.n_fast, self.n_slow, self.n_macd, self.price_col)\n",
    "            except:\n",
    "                pass\n",
    "            signal_data_df = signal_df\n",
    "\n",
    "        # v1 is the version of generating the og macd signals\n",
    "        signal_data_df['SIGNAL_DIRECTION'] = signal_data_df['SIGNAL_STATUS'].apply(lambda x: TimeSeriesToolbox.make_numeric_signals(x))\n",
    "        print(\"signal_data_df\", signal_data_df.head(3))\n",
    "        signal_data_df['SIGNAL_DIRECTION_DIFF'] = signal_data_df.groupby([self.code_col])['SIGNAL_DIRECTION'].diff()\n",
    "        signal_data_df['SIGNAL_ACTION'] = signal_data_df['SIGNAL_DIRECTION_DIFF'].apply(lambda x: \"LONG\" if x==2 else(\"SHORT\" if x==-2 else \"NO CHANGE\"))\n",
    "#         print(signal_data_df)\n",
    "        most_recent_signals = signal_data_df.groupby([self.code_col])[[self.date_col,self.code_col,'SIGNAL_STATUS','SIGNAL_ACTION']].tail(1)\n",
    "        df_actions = most_recent_signals[most_recent_signals[\"SIGNAL_ACTION\"]!=\"NO CHANGE\"]\n",
    "        return signal_data_df, most_recent_signals, df_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "class RiskParity(object):\n",
    "    \n",
    "    def __init__(self, stocks_path, tickers, \n",
    "                 date_col, code_col, price_col, \n",
    "                 ticker_type, asset_name, draw_pie_graph):\n",
    "        \n",
    "        self.path = stocks_path\n",
    "        self.tickers = tickers\n",
    "        self.date_col = date_col\n",
    "        self.code_col = code_col\n",
    "        self.price_col = price_col\n",
    "        self.ticker_type = ticker_type\n",
    "        self.asset_name = asset_name\n",
    "        self.draw_pie_graph = draw_pie_graph\n",
    "        self.ticker_df_list = self.get_date_price_code_return_list()\n",
    "        self.tgt_returns = self.ticker_df_list\n",
    "        self.tgt_merged_returns = self.merge_dfs_by_ticker(self.tgt_returns, \n",
    "                                                           self.date_col)\n",
    "        self.wts, self.risk = self.get_smart_weight(self.tgt_merged_returns, \n",
    "                                                    method='risk parity', \n",
    "                                                    cov_adjusted=False, \n",
    "                                                    wts_adjusted=False)\n",
    "        self.df_wts, self.risk_parity_tickers, self.weights = self.get_df_wts()\n",
    "        \n",
    "        \n",
    "    # Get date_col, price_col, code_col, pct_chg_col\n",
    "    def get_date_price_code_return_list(self):\n",
    "        # for etf data cols are 'date', 'close', 'code'\n",
    "        ticker_df_list = []\n",
    "        for ticker in self.tickers:\n",
    "            try:\n",
    "                ticker_df = pd.read_csv(self.path+ticker+\".csv\")\n",
    "                ticker_df = ticker_df.sort_values(self.date_col)\n",
    "                ticker_df = ticker_df[[self.date_col, \n",
    "                                       self.price_col, \n",
    "                                       self.code_col]]\n",
    "                ticker_df['pct_chg'] = ticker_df[self.price_col].pct_change()\n",
    "                ticker_df = ticker_df[[self.date_col, 'pct_chg']].dropna()\n",
    "                ticker_df.columns = [self.date_col, ticker]\n",
    "                ticker_df_list.append(ticker_df)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        return ticker_df_list\n",
    "    \n",
    "    \n",
    "    def merge_dfs_by_ticker(self, ticker_df_list, date_col):\n",
    "        merged_all = reduce(lambda left, right: pd.merge(left, right, on=date_col), ticker_df_list)\n",
    "#         merged_all = reduce(merge_df_for_reduce, ticker_df_list)\n",
    "        merged_all.set_index(self.date_col, inplace=True)\n",
    "        merged_all.dropna(how=\"all\", axis = 1, inplace = True)\n",
    "        merged_all.fillna(method=\"ffill\", inplace = True)\n",
    "        return merged_all\n",
    "        \n",
    "        \n",
    "    def get_smart_weight(self, pct, method, cov_adjusted, wts_adjusted):\n",
    "        if cov_adjusted == False:\n",
    "            #协方差矩阵\n",
    "            cov_mat = pct.cov()\n",
    "        else:\n",
    "            #调整后的半衰协方差矩阵\n",
    "            cov_mat = pct.iloc[:len(pct)/4].cov()*(1/10.) + pct.iloc[len(pct)/4+1:len(pct)/2].cov()*(2/10.) +\\\n",
    "                pct.iloc[len(pct)/2+1:len(pct)/4*3].cov()*(3/10.) + pct.iloc[len(pct)/4*3+1:].cov()*(4/10.)\n",
    "        if not isinstance(cov_mat, pd.DataFrame):\n",
    "            raise ValueError('cov_mat should be pandas DataFrame！')\n",
    "\n",
    "        omega = np.matrix(cov_mat.values)  # 协方差矩阵\n",
    "        \n",
    "        a, b = np.linalg.eig(np.array(cov_mat)) #a为特征值,b为特征向量\n",
    "        a = np.matrix(a)\n",
    "        b = np.matrix(b)\n",
    "        # 定义目标函数\n",
    "    \n",
    "        def fun1(x):\n",
    "            tmp = (omega * np.matrix(x).T).A1\n",
    "            risk = x * tmp/ np.sqrt(np.matrix(x) * omega * np.matrix(x).T).A1[0]\n",
    "            delta_risk = [sum((i - risk)**2) for i in risk]\n",
    "            return sum(delta_risk)\n",
    "\n",
    "        def fun2(x):\n",
    "            tmp = (b**(-1) * omega * np.matrix(x).T).A1\n",
    "            risk = (b**(-1)*np.matrix(x).T).A1 * tmp/ np.sqrt(np.matrix(x) * omega * np.matrix(x).T).A1[0]\n",
    "            delta_risk = [sum((i - risk)**2) for i in risk]\n",
    "            return sum(delta_risk)\n",
    "    \n",
    "        # 初始值 + 约束条件 \n",
    "        x0 = np.ones(omega.shape[0]) / omega.shape[0]  \n",
    "        bnds = tuple((0,None) for x in x0)\n",
    "        cons = ({'type':'eq', 'fun': lambda x: sum(x) - 1})\n",
    "        options={'disp':False, 'maxiter':1000, 'ftol':1e-20}\n",
    "        \n",
    "        \n",
    "        #------------------问题出在这里------------------\n",
    "        if method == 'risk parity':\n",
    "            res = minimize(fun1, x0, bounds=bnds, constraints=cons, method='SLSQP', options=options)        \n",
    "        elif method == 'pc risk parity':\n",
    "            res = minimize(fun2, x0, bounds=bnds, constraints=cons, method='SLSQP', options=options)\n",
    "        #------------------------------------\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('method error！！！')\n",
    "            \n",
    "        # 权重调整\n",
    "        if res['success'] == False:\n",
    "            # print res['message']\n",
    "            pass\n",
    "        wts = pd.Series(index=cov_mat.index, data=res['x'])\n",
    "\n",
    "        if wts_adjusted == True:\n",
    "            wts[wts < 0.0001]=0.0\n",
    "            wts = wts / wts.sum()\n",
    "        elif wts_adjusted == False:\n",
    "            wts = wts / wts.sum()\n",
    "        else:\n",
    "            raise ValueError('wts_adjusted should be True/False！')\n",
    "\n",
    "        risk = pd.Series(wts * (omega * np.matrix(wts).T).A1 / np.sqrt(np.matrix(wts) * omega * np.matrix(wts).T).A1[0],index = cov_mat.index)\n",
    "        risk[risk<0.0] = 0.0\n",
    "        return wts,risk\n",
    "    \n",
    "        \n",
    "    def get_df_wts(self):\n",
    "        df_wts = pd.DataFrame(self.wts)\n",
    "        df_wts.reset_index(inplace = True)\n",
    "        df_wts.columns = [self.asset_name, 'weight']\n",
    "        risk_parity_tickers = list(df_wts[self.asset_name])\n",
    "        weights = list(df_wts['weight'])\n",
    "        return df_wts, risk_parity_tickers, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mannually check our current position holdings for potential exit signals:\n",
    "cur_positions = [\n",
    "#     \"510180\",#180ETF\n",
    "#     \"510300\",#300ETF\n",
    "#     \"510810\",#上海国企\n",
    "#     \"510850\",#工银上50\n",
    "#     \"510880\",#红利ETF\n",
    "#     '512000', #券商ETF -\n",
    "#     '512010',#医药ETF\n",
    "#     \"512400\",#有色ETF\n",
    "#     \"512660\",#军工ETF\n",
    "#     '512290',#生物医药ETF -   \n",
    "    \"512380\", #MSCI中国指数\n",
    "    '512690',#酒ETF\n",
    "#     '512800',#银行ETF\n",
    "#     '512880',#证券ETF -\n",
    "     '512980', #传媒ETF\n",
    "    '159928',#消费ETF\n",
    "\n",
    "#     '513050',#中概互联网\n",
    "#     '513100',#纳指ETF\n",
    "#     '518880',#黄金ETF\n",
    "#     \"159905\",#深红利\n",
    "    \"159910\", #深100ETF\n",
    "#     \"159920\",#恒生ETF\n",
    "    \"159928\", #消费ETF\n",
    "#     \"159959\", #央企ETF -\n",
    "#     \"159939\"# 信息技术\n",
    "    '159938',#医药 -\n",
    "    '159952', #创业ETF\n",
    "#     ''#券商ETF\n",
    "#     '512960',#央调ETF\n",
    "#     ''#证券ETF\n",
    "    '513500'#标普500\n",
    "#     \"513100\"#纳指\n",
    "    \n",
    "]\n",
    "len(cur_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating MACD Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal_data_df          date   open  close   high    low     volume    code  MACD_Diff  \\\n",
      "0  2013-07-29  2.633  2.626  2.640  2.614  1404335.0  518880        NaN   \n",
      "1  2013-07-30  2.632  2.646  2.648  2.632   929931.0  518880        NaN   \n",
      "2  2013-07-31  2.643  2.657  2.659  2.640   699761.0  518880        NaN   \n",
      "\n",
      "   MACD_Diff_EMA  MACD SIGNAL_STATUS  SIGNAL_DIRECTION  \n",
      "0            NaN   NaN         无信号状态                 0  \n",
      "1            NaN   NaN         无信号状态                 0  \n",
      "2            NaN   NaN         无信号状态                 0  \n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    stocks_path = \"/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/data/CH_database/\"\n",
    "    etfs_df = pd.read_csv(\"filtered_50_etfs_by_vol_20200224.csv\")\n",
    "    tickers = list(etfs_df['etf'].str.split(\".\",expand = True)[0])\n",
    "#     date_col = 'trade_date'\n",
    "#     code_col = 'ts_code'\n",
    "#     price_col = 'close'\n",
    "    date_col = 'date'\n",
    "    code_col = 'code'\n",
    "    price_col = 'close'\n",
    "    ticker_type = 'string'\n",
    "    asset_name = \"code\"\n",
    "    tgt_wts_mutiplier = 4\n",
    "    account_value = 100000\n",
    "    \n",
    "#     # ========For calculating MACD signals========\n",
    "    n_fast = 12\n",
    "    n_slow = 26\n",
    "    n_macd = 9\n",
    "    macd = MACDSignals(stocks_path, \n",
    "                        tickers, \n",
    "                        date_col, \n",
    "                        code_col, \n",
    "                        price_col, \n",
    "                        n_fast, \n",
    "                        n_slow, \n",
    "                        n_macd, \n",
    "                        ticker_type)\n",
    "    macd_signals, last_macd_signals, df_actions = macd.calc_macd_signals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete tickers that are not up-to-date to make sure RP can function well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Tickers Left is:  49\n"
     ]
    }
   ],
   "source": [
    "last_date = last_macd_signals['date'].values[-1]\n",
    "tickers = list(last_macd_signals[last_macd_signals['date']==last_date]['code'])\n",
    "print(\"The number of Tickers Left is: \", len(tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Risk-Parity Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========For calculating risk-parity weights========\n",
    "risk_parity = RiskParity(stocks_path,\n",
    "                          tickers,\n",
    "                          date_col,\n",
    "                          code_col,\n",
    "                          price_col,\n",
    "                          ticker_type,\n",
    "                          asset_name,\n",
    "                          True)\n",
    "\n",
    "df_wts, risk_parity_tickers, weights = risk_parity.get_df_wts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if there's any new position to be entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159920\n",
      "510180\n",
      "512010\n",
      "512330\n",
      "512180\n"
     ]
    }
   ],
   "source": [
    "df_actions_with_weights = TimeSeriesToolbox.merge_weights_and_signal(df_actions,\n",
    "                                                                 df_wts,\n",
    "                                                                 stocks_path,\n",
    "                                                                 code_col,\n",
    "                                                                 date_col,\n",
    "                                                                 price_col,\n",
    "                                                                 tgt_wts_mutiplier,\n",
    "                                                                 account_value)\n",
    "#     PlotToolbox.pie_graph(weights, risk_parity_tickers, 8, 8, \"Risk Parity Allocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>SIGNAL_STATUS</th>\n",
       "      <th>SIGNAL_ACTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>518880</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>513500</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>513100</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159920</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8865</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510500</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>513050</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510180</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14255</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510900</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159901</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17165</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512290</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18838</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512010</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159928</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21527</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512660</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22279</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512800</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512400</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25023</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159919</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25351</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512690</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27945</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510050</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29304</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159939</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30683</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159938</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32799</th>\n",
       "      <td>2020/8/7</td>\n",
       "      <td>159915</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35145</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159905</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37739</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510880</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38989</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512330</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39954</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512000</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40946</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512880</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41782</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512900</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43602</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159922</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46196</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159902</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47165</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510810</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159949</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49943</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510510</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50878</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512100</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510330</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54716</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510300</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55353</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512980</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57167</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510310</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57971</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159952</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59256</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512500</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60586</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512990</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60953</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510850</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62168</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510360</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62563</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159959</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62958</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512960</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63353</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512950</td>\n",
       "      <td>空头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63913</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512180</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64487</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512160</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512280</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65594</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512090</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65923</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512380</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    code SIGNAL_STATUS SIGNAL_ACTION\n",
       "1731   2020-09-02  518880          空头状态     NO CHANGE\n",
       "3349   2020-09-02  513500          多头状态     NO CHANGE\n",
       "5131   2020-09-02  513100          多头状态     NO CHANGE\n",
       "7047   2020-09-02  159920          空头状态         SHORT\n",
       "8865   2020-09-02  510500          空头状态     NO CHANGE\n",
       "9748   2020-09-02  513050          多头状态     NO CHANGE\n",
       "12340  2020-09-02  510180          多头状态          LONG\n",
       "14255  2020-09-02  510900          空头状态     NO CHANGE\n",
       "16847  2020-09-02  159901          多头状态     NO CHANGE\n",
       "17165  2020-09-02  512290          空头状态     NO CHANGE\n",
       "18838  2020-09-02  512010          多头状态          LONG\n",
       "20535  2020-09-02  159928          多头状态     NO CHANGE\n",
       "21527  2020-09-02  512660          空头状态     NO CHANGE\n",
       "22279  2020-09-02  512800          空头状态     NO CHANGE\n",
       "23010  2020-09-02  512400          空头状态     NO CHANGE\n",
       "25023  2020-09-02  159919          多头状态     NO CHANGE\n",
       "25351  2020-09-02  512690          多头状态     NO CHANGE\n",
       "27945  2020-09-02  510050          多头状态     NO CHANGE\n",
       "29304  2020-09-02  159939          空头状态     NO CHANGE\n",
       "30683  2020-09-02  159938          多头状态     NO CHANGE\n",
       "32799    2020/8/7  159915          多头状态     NO CHANGE\n",
       "35145  2020-09-02  159905          多头状态     NO CHANGE\n",
       "37739  2020-09-02  510880          空头状态     NO CHANGE\n",
       "38989  2020-09-02  512330          多头状态          LONG\n",
       "39954  2020-09-02  512000          空头状态     NO CHANGE\n",
       "40946  2020-09-02  512880          空头状态     NO CHANGE\n",
       "41782  2020-09-02  512900          空头状态     NO CHANGE\n",
       "43602  2020-09-02  159922          空头状态     NO CHANGE\n",
       "46196  2020-09-02  159902          空头状态     NO CHANGE\n",
       "47165  2020-09-02  510810          空头状态     NO CHANGE\n",
       "48168  2020-09-02  159949          多头状态     NO CHANGE\n",
       "49943  2020-09-02  510510          空头状态     NO CHANGE\n",
       "50878  2020-09-02  512100          空头状态     NO CHANGE\n",
       "52701  2020-09-02  510330          多头状态     NO CHANGE\n",
       "54716  2020-09-02  510300          多头状态     NO CHANGE\n",
       "55353  2020-09-02  512980          多头状态     NO CHANGE\n",
       "57167  2020-09-02  510310          多头状态     NO CHANGE\n",
       "57971  2020-09-02  159952          多头状态     NO CHANGE\n",
       "59256  2020-09-02  512500          空头状态     NO CHANGE\n",
       "60586  2020-09-02  512990          多头状态     NO CHANGE\n",
       "60953  2020-09-02  510850          多头状态     NO CHANGE\n",
       "62168  2020-09-02  510360          多头状态     NO CHANGE\n",
       "62563  2020-09-02  159959          空头状态     NO CHANGE\n",
       "62958  2020-09-02  512960          空头状态     NO CHANGE\n",
       "63353  2020-09-02  512950          空头状态     NO CHANGE\n",
       "63913  2020-09-02  512180          多头状态          LONG\n",
       "64487  2020-09-02  512160          多头状态     NO CHANGE\n",
       "65043  2020-09-02  512280          多头状态     NO CHANGE\n",
       "65594  2020-09-02  512090          多头状态     NO CHANGE\n",
       "65923  2020-09-02  512380          多头状态     NO CHANGE"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_macd_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>SIGNAL_STATUS</th>\n",
       "      <th>SIGNAL_ACTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>513500</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>513100</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>513050</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510180</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159901</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18838</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512010</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159928</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25023</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159919</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25351</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512690</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27945</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510050</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30683</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159938</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32799</th>\n",
       "      <td>2020/8/7</td>\n",
       "      <td>159915</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35145</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159905</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38989</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512330</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159949</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510330</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54716</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510300</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55353</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512980</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57167</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510310</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57971</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>159952</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60586</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512990</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60953</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510850</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62168</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>510360</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63913</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512180</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>LONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64487</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512160</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512280</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65594</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512090</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65923</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>512380</td>\n",
       "      <td>多头状态</td>\n",
       "      <td>NO CHANGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    code SIGNAL_STATUS SIGNAL_ACTION\n",
       "3349   2020-09-02  513500          多头状态     NO CHANGE\n",
       "5131   2020-09-02  513100          多头状态     NO CHANGE\n",
       "9748   2020-09-02  513050          多头状态     NO CHANGE\n",
       "12340  2020-09-02  510180          多头状态          LONG\n",
       "16847  2020-09-02  159901          多头状态     NO CHANGE\n",
       "18838  2020-09-02  512010          多头状态          LONG\n",
       "20535  2020-09-02  159928          多头状态     NO CHANGE\n",
       "25023  2020-09-02  159919          多头状态     NO CHANGE\n",
       "25351  2020-09-02  512690          多头状态     NO CHANGE\n",
       "27945  2020-09-02  510050          多头状态     NO CHANGE\n",
       "30683  2020-09-02  159938          多头状态     NO CHANGE\n",
       "32799    2020/8/7  159915          多头状态     NO CHANGE\n",
       "35145  2020-09-02  159905          多头状态     NO CHANGE\n",
       "38989  2020-09-02  512330          多头状态          LONG\n",
       "48168  2020-09-02  159949          多头状态     NO CHANGE\n",
       "52701  2020-09-02  510330          多头状态     NO CHANGE\n",
       "54716  2020-09-02  510300          多头状态     NO CHANGE\n",
       "55353  2020-09-02  512980          多头状态     NO CHANGE\n",
       "57167  2020-09-02  510310          多头状态     NO CHANGE\n",
       "57971  2020-09-02  159952          多头状态     NO CHANGE\n",
       "60586  2020-09-02  512990          多头状态     NO CHANGE\n",
       "60953  2020-09-02  510850          多头状态     NO CHANGE\n",
       "62168  2020-09-02  510360          多头状态     NO CHANGE\n",
       "63913  2020-09-02  512180          多头状态          LONG\n",
       "64487  2020-09-02  512160          多头状态     NO CHANGE\n",
       "65043  2020-09-02  512280          多头状态     NO CHANGE\n",
       "65594  2020-09-02  512090          多头状态     NO CHANGE\n",
       "65923  2020-09-02  512380          多头状态     NO CHANGE"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_macd_signals[last_macd_signals['SIGNAL_STATUS']=='多头状态']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge current position and target positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal_data_df              date   open  close   high    low    volume    code  MACD_Diff  \\\n",
      "63479  2019-04-30  0.960  0.973  0.980  0.960  176255.0  512380        NaN   \n",
      "63480  2019-05-06  0.944  0.912  0.944  0.902  254559.0  512380        NaN   \n",
      "63481  2019-05-07  0.911  0.923  0.929  0.907  108649.0  512380        NaN   \n",
      "\n",
      "       MACD_Diff_EMA  MACD SIGNAL_STATUS  SIGNAL_DIRECTION  \n",
      "63479            NaN   NaN         无信号状态                 0  \n",
      "63480            NaN   NaN         无信号状态                 0  \n",
      "63481            NaN   NaN         无信号状态                 0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/miaoyuesun/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a6d519a11e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtgt_cur_pos_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeriesToolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_current_pos_with_target_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_macd_signals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-7ac314a3a67e>\u001b[0m in \u001b[0;36mmerge_current_pos_with_target_pos\u001b[0;34m(path, cur_positions, tgt_last_macd_signals)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcur_pos_macd_signals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mcur_pos_last_macd_signals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mcur_pos_df_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_pos_macd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_macd_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mcur_pos_last_macd_signals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TYPE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CUR_POS'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtgt_cur_macd_signal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_pos_last_macd_signals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_last_macd_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdate_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcode_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-a4b81e41ee6d>\u001b[0m in \u001b[0;36mcalc_macd_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msignal_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGNAL_DIRECTION'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGNAL_STATUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTimeSeriesToolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_numeric_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"signal_data_df\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msignal_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGNAL_DIRECTION_DIFF'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGNAL_DIRECTION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0msignal_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGNAL_ACTION'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGNAL_DIRECTION_DIFF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"LONG\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SHORT\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NO CHANGE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#         print(signal_data_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 if not re.search(\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     @Substitution(\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         return self._wrap_applied_output(\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnot_indexed_same\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         )\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_wrap_applied_output\u001b[0;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnot_indexed_same\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_indexed_same\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# possible that Series -> DataFrame by applied function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_concat_objects\u001b[0;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4029\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4030\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4031\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4033\u001b[0m     def drop(\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4541\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4542\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4543\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4544\u001b[0m         ).__finalize__(self)\n\u001b[1;32m   4545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4564\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4565\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4566\u001b[0;31m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4567\u001b[0m             )\n\u001b[1;32m   4568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4610\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4611\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4612\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4613\u001b[0m             )\n\u001b[1;32m   4614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3097\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3099\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "tgt_cur_pos_df = TimeSeriesToolbox.merge_current_pos_with_target_pos(stocks_path, cur_positions, last_macd_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recent_goldcross_close(close, signal_diff):\n",
    "    if signal_diff == 1 or signal_diff == 2:\n",
    "        return close\n",
    "\n",
    "    \n",
    "    \n",
    "macd_signals['recent_goldcross'] = macd_signals.apply(lambda row: find_recent_goldcross_close(row['close'],row['SIGNAL_DIRECTION_DIFF']), axis=1)\n",
    "# forward-fill all NaNs for the recent_goldcross to pave way for calculating the pct_diff between current \n",
    "# close and the rencent goldcross close\n",
    "macd_signals['recent_goldcross_ffill'] = macd_signals.groupby(\"code\")['recent_goldcross'].apply(lambda x: x.fillna(method=\"ffill\"))\n",
    "macd_signals['pctchg_from_recent_goldcrossclose'] = (macd_signals['close']-macd_signals['recent_goldcross_ffill'])/macd_signals['recent_goldcross_ffill']\n",
    "macd_signals['reentry_rank'] = macd_signals.groupby([\"date\"])['pctchg_from_recent_goldcrossclose'].rank(ascending = True)\n",
    "last_day = macd_signals['date'].values[-1]\n",
    "macd_signals_reentry = macd_signals[macd_signals['date']==last_day][macd_signals['pctchg_from_recent_goldcrossclose']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reentry_tickers = list(macd_signals_reentry['code'])\n",
    "tickers_to_reenter = []\n",
    "for ticker in all_reentry_tickers:\n",
    "    if ticker not in cur_positions:\n",
    "        tickers_to_reenter.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_reenter_df = pd.DataFrame(tickers_to_reenter, columns=['code'])\n",
    "df_actions_with_weights_reentry = df_wts.merge(tickers_to_reenter_df, on = ['code'])\n",
    "macd_signals_reentry = macd_signals[macd_signals['date']==last_day]\n",
    "df_actions_with_weights_reentry = df_actions_with_weights_reentry.merge(macd_signals_reentry, on = 'code')\n",
    "df_actions_with_weights_reentry['weight_enlarged'] = df_actions_with_weights_reentry['weight']*tgt_wts_mutiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions_with_weights_reentry['tgt_shares'] = account_value*\\\n",
    "                                                    df_actions_with_weights_reentry['weight_enlarged']/\\\n",
    "                                                    df_actions_with_weights_reentry[price_col]\n",
    "\n",
    "df_actions_with_weights_reentry = df_actions_with_weights_reentry[['code','date','SIGNAL_STATUS','SIGNAL_ACTION',\\\n",
    "                                                                   'weight_enlarged','close','tgt_shares',\\\n",
    "                                                                   'pctchg_from_recent_goldcrossclose','reentry_rank']]\n",
    "df_actions_with_weights_reentry.sort_values('reentry_rank', ascending=True, inplace=True)\n",
    "df_actions_with_weights_reentry_L = df_actions_with_weights_reentry[df_actions_with_weights_reentry['SIGNAL_STATUS']==\"多头状态\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions_with_weights_reentry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions_with_weights_reentry_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_reentry_tickers = list(df_actions_with_weights_reentry_L['code'])\n",
    "print(\"Tickers that need to be re-entered: \", selected_reentry_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check current positions & new positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show if there are any actions needed to be made for our current positions\n",
    "tgt_cur_pos_df[tgt_cur_pos_df['TYPE_x']==\"CUR_POS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any new positions to be entered\n",
    "tgt_cur_pos_df[(tgt_cur_pos_df['TYPE_x']!=\"CUR_POS\")&(tgt_cur_pos_df['SIGNAL_ACTION_y']!=\"NO CHANGE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_actions_with_weights = df_actions_with_weights[df_actions_with_weights['SIGNAL_ACTION']=='LONG']\n",
    "except:\n",
    "    df_actions_with_weights = []\n",
    "\n",
    "try:\n",
    "    df_actions_tickers = list(df_actions_with_weights['code'])\n",
    "except:\n",
    "    df_actions_tickers = []\n",
    "\n",
    "symbol_list_to_backtest = df_actions_tickers+selected_reentry_tickers\n",
    "print(\"All tickers that to be entered before backtesting are:\", symbol_list_to_backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest and Filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CH_backtest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_performances = {}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for ticker in symbol_list_to_backtest:\n",
    "    # csv_dir = REPLACE_WITH_YOUR_CSV_DIR_HERE\n",
    "        equity_folder = \"./\"\n",
    "        csv_dir = \"/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/data/CH_database/\"\n",
    "#         data_cols = ['trade_date', 'open', 'high','low', 'close', 'volume','ts_code'] #for ETFs # 要改代码\n",
    "#         data_cols = ['ts_code','trade_date','open','high','low','close','pre_close','change','pct_chg','vol','amount'] #for stocks\n",
    "#         commissions = 5 # RMB/USD per trade #要改代码\n",
    "        initial_capital = 1000000.0\n",
    "        start_date = datetime.datetime(1991,12,1,0,0,0)\n",
    "        start_date_str = str(start_date)\n",
    "        heartbeat = 0.0\n",
    "#         price_col = \"close\" #要改代码\n",
    "#         qty = 5000 # 要改代码\n",
    "        backtest = Backtest(csv_dir, \n",
    "                            [ticker], \n",
    "                            initial_capital, \n",
    "                            heartbeat,\n",
    "                            start_date,\n",
    "                            HistoricCSVDataHandler, \n",
    "                            SimulatedExecutionHandler, \n",
    "                            Portfolio, \n",
    "    #                         MovingAverageCrossStrategy,\n",
    "                           MovingAverageConvergenceDivergence)\n",
    "\n",
    "        backtest.simulate_trading()\n",
    "        df_equity = pd.read_csv(ticker+\"_performance\"+\".csv\")\n",
    "        df_equity.drop_duplicates(\"datetime\", inplace = True)\n",
    "        df_equity =df_equity[df_equity['datetime']>start_date_str]\n",
    "        df_equity.index = df_equity['datetime']\n",
    "        df_equity = df_equity[df_equity['total'].map(lambda x: str(x)!=\"nan\")]\n",
    "        df_equity.columns = ['datetime', 'market_value', 'cash', 'commission', 'total', 'returns',\n",
    "        'equity_curve', 'drawdown']\n",
    "        df_equity_copy = df_equity.copy()\n",
    "        data = df_equity_copy\n",
    "#         win_rate, mean_win_loss_ratio, bt_score, profits = performance(data)\n",
    "        single_stats = performance(data)\n",
    "#         print(\"TICKER: \", ticker)\n",
    "        ticker_performances[ticker] = single_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ticker_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions_with_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions_with_weights_reentry_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Signal Status on Long/Shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD_long_short_counts(macd_signals, date_col, code_col):\n",
    "    long_short_counts = macd_signals.groupby([date_col,'SIGNAL_DIRECTION'])[code_col].count()\n",
    "    long_short_counts_df = pd.DataFrame(long_short_counts)\n",
    "    long_short_counts_df.reset_index(inplace=True)\n",
    "    long_counts_df = long_short_counts_df[long_short_counts_df['SIGNAL_DIRECTION']==1]\n",
    "    short_counts_df = long_short_counts_df[long_short_counts_df['SIGNAL_DIRECTION']==-1]\n",
    "    long_short_counts_df_merged = long_counts_df.merge(short_counts_df, on = date_col)\n",
    "    long_short_counts_df_merged['long_short_ratio'] = long_short_counts_df_merged['code_x']/(\\\n",
    "                                                                            long_short_counts_df_merged['code_x']+\\\n",
    "                                                                            long_short_counts_df_merged['code_y'])\n",
    "    long_short_counts_df_merged.index = pd.to_datetime(long_short_counts_df_merged[date_col])\n",
    "    return long_short_counts_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macd_long_short_counts = MACD_long_short_counts(macd_signals, date_col, code_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = macd_long_short_counts[date_col].values[-1]\n",
    "macd_long_short_counts[['code_x','code_y']].tail(100).plot(figsize = (18,10));\n",
    "plt.title(\"Daily Number of Long Signals vs Short Signals for 50 ETFs by {}\".format(today), fontsize = 17);\n",
    "\n",
    "macd_long_short_counts['long_short_ratio'].tail(100).plot(figsize = (18,10))\n",
    "long_short_ratio = macd_long_short_counts['long_short_ratio'].values[-1]\n",
    "plt.title(\"Long_Short_Ratio: {}, by {}\".format(round(long_short_ratio,2), today), fontsize =15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
