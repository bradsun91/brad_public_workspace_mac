{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from datetime import datetime\n",
    "pd.set_option('max_colwidth',200)\n",
    "# import yfinance as yf\n",
    "import tushare as ts\n",
    "ts.set_token('2f31c3932ead9fcc3830879132cc3ec8df3566550f711889d4a30f67')\n",
    "import time, urllib\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Company Numbers by today:  3754\n"
     ]
    }
   ],
   "source": [
    "def get_data(code,start,end):\n",
    "    df = ts.pro_bar(ts_code=code, adj='qfq', start_date=start, end_date=end)\n",
    "    return df\n",
    "\n",
    "#获取当前交易日最新的股票代码和简称\n",
    "def get_code():\n",
    "    codes = pro.stock_basic(list_status='L').ts_code.values\n",
    "    return codes\n",
    "\n",
    "\n",
    "def download_tushare_stocks_data(start, end, ch_db_path, ticker_list):\n",
    "    count = 1\n",
    "    for ticker in ticker_list:\n",
    "        if count%200==0:\n",
    "            print(\"=======================Sleeping======================\")\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            if not os.path.exists(ch_db_path+ticker+\".csv\"):\n",
    "                print(\"{} is new, start downloading now...\".format(ticker))\n",
    "                try:\n",
    "                    data = get_data(ticker)\n",
    "    #                 print(data)\n",
    "                    data['trade_date'] = data['trade_date'].astype(str)\n",
    "                    data['trade_date'] = data['trade_date'].apply(lambda x:x[:4]+\"-\"+x[4:6]+\"-\"+x[6:] if len(x)!=10 else x)\n",
    "                    data.sort_values(\"trade_date\", inplace = True)\n",
    "                    data.to_csv(ch_db_path+ticker+\".csv\", index = False)\n",
    "                    print(\"{} data file created: {}\".format(ticker, end))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "            else:\n",
    "                print(\"Already have data csv for {}\".format(ticker))\n",
    "                hist_data = pd.read_csv(ch_db_path+ticker+\".csv\")   \n",
    "                hist_data['trade_date'] = hist_data['trade_date'].astype(str)\n",
    "                hist_data['trade_date'] = hist_data['trade_date'].apply(lambda x:x[:4]+\"-\"+x[4:6]+\"-\"+x[6:] if len(x)!=10 else x)\n",
    "                hist_data.to_csv(ch_db_path+ticker+\".csv\", index = False)\n",
    "                hist_data = pd.read_csv(ch_db_path+ticker+\".csv\")\n",
    "                try:\n",
    "                    hist_data_last_date = hist_data['trade_date'].values[-1]        \n",
    "                    if today > hist_data_last_date:\n",
    "                        print(\"Needs to update, start updating new data for {} now...\".format(ticker))\n",
    "                        update_start = hist_data_last_date\n",
    "                        update_end = today\n",
    "                        with eventlet.Timeout(60,False):\n",
    "                            try:\n",
    "                                new_data = get_data(ticker, update_start, update_end)\n",
    "                                new_data['trade_date'] = new_data['trade_date'].astype(str)\n",
    "                                new_data['trade_date'] = new_data['trade_date'].apply(lambda x:x[:4]+\"-\"+x[4:6]+\"-\"+x[6:])\n",
    "                                new_data.to_csv(ch_db_path+ticker+\".csv\", mode='a', header=False, index = False)\n",
    "                                updated_duplicated_df = pd.read_csv(ch_db_path+ticker+\".csv\")\n",
    "                                updated_df = updated_duplicated_df.drop_duplicates(\"trade_date\")\n",
    "                                updated_df.sort_values(\"trade_date\", inplace = True)\n",
    "                                updated_df.to_csv(ch_db_path+ticker+\".csv\", index = False)\n",
    "                                print(\"New data updated till today for {}!\".format(ticker))\n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "            #             print(\"Timed Out: Update Failed!\")\n",
    "                    else:\n",
    "                        print(\"There's no new data to update for {}.\".format(ticker))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "        #     print(\"Data Download/Update for {} is Finished.\".format(ticker))\n",
    "            print(\"=======================Executed: {}=======================\".format(count))\n",
    "        count+=1\n",
    "    print(\"【Updated Finished for today!】\")\n",
    "\n",
    "\n",
    "#设置token\n",
    "token='2f31c3932ead9fcc3830879132cc3ec8df3566550f711889d4a30f67'\n",
    "pro = ts.pro_api(token)\n",
    "codes = get_code()\n",
    "print(\"Public Company Numbers by today: \", len(codes))\n",
    "\n",
    "today = str(datetime.now().date())\n",
    "start = '20100101'\n",
    "end = today\n",
    "ch_db_path = \"/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/data/CH_database/\"\n",
    "ticker_list = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have data csv for 000001.SZ\n",
      "Needs to update, start updating new data for 000001.SZ now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaoyuesun/anaconda3/lib/python3.5/site-packages/pandas/compat/_optional.py:106: UserWarning: Pandas requires version '2.6.2' or newer of 'numexpr' (version '2.6.1' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/miaoyuesun/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data updated till today for 000001.SZ!\n",
      "=======================Executed: 1=======================\n",
      "Already have data csv for 000002.SZ\n",
      "Needs to update, start updating new data for 000002.SZ now...\n",
      "New data updated till today for 000002.SZ!\n",
      "=======================Executed: 2=======================\n",
      "Already have data csv for 000004.SZ\n",
      "Needs to update, start updating new data for 000004.SZ now...\n",
      "New data updated till today for 000004.SZ!\n",
      "=======================Executed: 3=======================\n",
      "Already have data csv for 000005.SZ\n",
      "Needs to update, start updating new data for 000005.SZ now...\n",
      "New data updated till today for 000005.SZ!\n",
      "=======================Executed: 4=======================\n",
      "Already have data csv for 000006.SZ\n",
      "Needs to update, start updating new data for 000006.SZ now...\n",
      "New data updated till today for 000006.SZ!\n",
      "=======================Executed: 5=======================\n",
      "Already have data csv for 000007.SZ\n",
      "Needs to update, start updating new data for 000007.SZ now...\n",
      "New data updated till today for 000007.SZ!\n",
      "=======================Executed: 6=======================\n",
      "Already have data csv for 000008.SZ\n",
      "Needs to update, start updating new data for 000008.SZ now...\n",
      "New data updated till today for 000008.SZ!\n",
      "=======================Executed: 7=======================\n",
      "Already have data csv for 000009.SZ\n",
      "Needs to update, start updating new data for 000009.SZ now...\n",
      "New data updated till today for 000009.SZ!\n",
      "=======================Executed: 8=======================\n",
      "Already have data csv for 000010.SZ\n",
      "Needs to update, start updating new data for 000010.SZ now...\n",
      "New data updated till today for 000010.SZ!\n",
      "=======================Executed: 9=======================\n",
      "Already have data csv for 000011.SZ\n",
      "Needs to update, start updating new data for 000011.SZ now...\n",
      "New data updated till today for 000011.SZ!\n",
      "=======================Executed: 10=======================\n",
      "Already have data csv for 000012.SZ\n",
      "Needs to update, start updating new data for 000012.SZ now...\n",
      "New data updated till today for 000012.SZ!\n",
      "=======================Executed: 11=======================\n",
      "Already have data csv for 000014.SZ\n",
      "Needs to update, start updating new data for 000014.SZ now...\n",
      "New data updated till today for 000014.SZ!\n",
      "=======================Executed: 12=======================\n",
      "Already have data csv for 000016.SZ\n",
      "Needs to update, start updating new data for 000016.SZ now...\n",
      "New data updated till today for 000016.SZ!\n",
      "=======================Executed: 13=======================\n",
      "Already have data csv for 000017.SZ\n",
      "Needs to update, start updating new data for 000017.SZ now...\n",
      "New data updated till today for 000017.SZ!\n",
      "=======================Executed: 14=======================\n",
      "Already have data csv for 000018.SZ\n",
      "Needs to update, start updating new data for 000018.SZ now...\n",
      "New data updated till today for 000018.SZ!\n",
      "=======================Executed: 15=======================\n",
      "Already have data csv for 000019.SZ\n",
      "Needs to update, start updating new data for 000019.SZ now...\n",
      "New data updated till today for 000019.SZ!\n",
      "=======================Executed: 16=======================\n",
      "Already have data csv for 000020.SZ\n",
      "Needs to update, start updating new data for 000020.SZ now...\n",
      "New data updated till today for 000020.SZ!\n",
      "=======================Executed: 17=======================\n",
      "Already have data csv for 000021.SZ\n",
      "Needs to update, start updating new data for 000021.SZ now...\n",
      "New data updated till today for 000021.SZ!\n",
      "=======================Executed: 18=======================\n",
      "Already have data csv for 000023.SZ\n",
      "Needs to update, start updating new data for 000023.SZ now...\n",
      "New data updated till today for 000023.SZ!\n",
      "=======================Executed: 19=======================\n",
      "Already have data csv for 000025.SZ\n",
      "Needs to update, start updating new data for 000025.SZ now...\n",
      "New data updated till today for 000025.SZ!\n",
      "=======================Executed: 20=======================\n",
      "Already have data csv for 000026.SZ\n",
      "Needs to update, start updating new data for 000026.SZ now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import eventlet\n",
    "eventlet.monkey_patch()\n",
    "\n",
    "download_tushare_stocks_data(start, end, ch_db_path, ticker_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
